[
["index.html", "Statistical Learning of Infectious Disease Data Analytics Chapter 1 Preface 1.1 Data Sets Used in Labs and Exercises 1.2 Acknowledgements 1.3 About the Author", " Statistical Learning of Infectious Disease Data Analytics Lily Wang 2021-02-18 Chapter 1 Preface The book is written for three audiences: (1) data scientists finding themselves doing modeling and forecasting in epidemilogy; (2) graduate students studying epidemiology; (3) graduate students doing a modeling and forecasting elective. For most sections, we only assume that readers are familiar with introductory statistics, and with high-school algebra. There are a couple of sections that also require knowledge of matrices, but these are flagged. At the end of each chapter we provide a list of “further reading.” In general, these lists comprise suggested textbooks that provide a more advanced or detailed treatment of the subject. Where there is no suitable textbook, we suggest journal articles that provide more information. We use R throughout the book and we intend students to learn how to forecast with R. R is free and available on almost every operating system. It is a wonderful tool for all statistical analysis, not just for forecasting. See the Using R appendix for instructions on installing and using R. Short Description: This book provides a quick start guide to infectious disease data analysis and visualization in R. You’ll learn, how to create static and interactive graphs. Long Description: This book will introduce readers to modern statistical models and state-of-the-art learning methods to analyze infectious disease data. Many of the key approaches, examples and case studies will be presented. The primary emphasis will be interpretation, inference and hands-on data analyses. This course also provides practical concepts and R computing skills to perform infectious disease data analysis and visualization. This book provides a quick start guide to infectious disease data analysis and visualization in R. You’ll learn, how to: Apply appropriate descriptive and inferential statistical techniques to infectious disease data and interpret results of statistical analyses in the context of public health research and evaluation; Develop skills in model building, investigating model assumptions, and interpreting results from statistical models with particular applications to epidemiologic and especially the infectious disease data; Develop the ability to use R to understand basic data structures, basic data processing skills, and basic data visualization skills; 1.1 Data Sets Used in Labs and Exercises In this textbook, we illustrate statistical learning methods for infectious disease data using applications from COVID-19 data. The slid package available on the book website contains a number of data sets that are required in order to perform the labs and exercises associated with this book. 1.2 Acknowledgements I am very appreciative of all the contributors to this immense open source project of R and R-Studio. I couldn’t have made this book without your contributions and the packages that you have developed. A special thanks go to Dr. Guannan Wang, Dr. Xinyi Li, Dr. Shan Yu, Miss Yueying Wang, Miss Zhiling Gu, Mr. Myungjin Kim for their help with the book. I would also like to thank Dr. Yihui Xie (Xie 2020) for his R Markdown package, which simplifies the writing of this book by having all content written in R Markdown. 1.3 About the Author Dr. Lily Wang is a tenured Professor of Statistics at Iowa State University. She received her Ph.D. in Statistics from Michigan State University in 2007. Prior to joining Iowa State in 2014, she was a tenure-track Assistant/tenured Associate Professor in the Department of Statistics at the University of Georgia 2007-2013/2013-2014. Her primary areas of research include developing cutting-edge statistical non/semi-parametric methods, statistical learning of large datasets with complex features, methodologies for functional data, imaging data, and spatiotemporal data, survey sampling, and the application of statistics to problems in economics, engineering, neuroimaging, epidemiology, environmental studies, and biomedical science. References "],
["intro.html", "Chapter 2 Introduction 2.1 Aims and Scope of This Book 2.2 The Structure of This Book", " Chapter 2 Introduction 2.1 Aims and Scope of This Book Epidemiologic data are paramount to targeting and implementing evidence-based control measures to protect the public’s health and safety. Nowhere are data more important than during a field epidemiologic investigation to identify the cause of an urgent public health problem that requires immediate intervention. Many of the steps to conducting a field investigation rely on identifying relevant existing data or collecting new data that address the key investigation objectives. In today’s information age, the challenge is not the lack of data but rather how to identify the most relevant data for meaningful results and how to combine data from various sources that might not be standardized or interoperable to enable analysis. Accessing or collecting clean, valid, reliable, and timely data challenges most field epidemiologic investigations. Infectious disease learning requires lots of iteration between data manipulation, visualization, and modeling. The purpose of this book is to provide an overview of modern data science tools and methods that have been developed specifically to analyze infectious disease data. The readers are assumed to have a background in high school mathematics and introductory-level statistics, but no specialist knowledge of infectious diseases is assumed. Since the topic of this book is an enormous one, we do not claim to provide comprehensive coverage of all existing methods. However, we will describe many of the critical approaches, and throughout, there will be many examples and case studies. This book serves the complementary purpose of introducing graduate students and others to the field of infectious disease data analysis, acting as a reference for researchers in this field, and helping practicing data scientists and infectious disease epidemiologists to develop the ability to use R to understand basic data structures, basic data processing skills, and basic data visualization skills. 2.2 The Structure of This Book 2.2.1 Infectious disease data The material in this book is concerned with the statistical analysis of quantitative data obtained by observing the spread of infectious diseases. According to Porta (2014): Infectious disease (or communicable disease) is defined as an illness caused by a specific infectious agent or its toxic product that results from transmission of that agent or its products from an infected person, animal, or reservoir to a susceptible host, either directly or indirectly through an intermediate plant or animal host, vector or inanimate environment. Surveillance systems generate data that help public health officials understand existing and emerging infectious diseases. Without a proper understanding of the health problem (etiology, distribution, and mechanism of infection), it will be difficult to ameliorate the health issue. Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus. The current COVID-19 pandemic raises important questions about opening, sharing and using data, and highlights the challenges associated with data use. It is well known that data is critical to understanding the impact of infectious disease, but also to inform the appropriate response, planning and allocation of resources. 2.2.2 Basic characteristics of the infection process Reservoir of infection, also called primary source of infection, is a location (person, animal, arthropod, plant, soil, or substance) in which the infectious agent finds conditions that permit it to survive and multiply and from where it can be transmitted to another susceptible host. See Barreto, Teixeira, and Carmo (2006). For the infection of a new host to occur, there must be an opportunity for a susceptible host to be exposed to the infectious agent—that is, there must be contact between the agent and the host. The infectious disease is transmitted to a susceptible host, when the individual takes in a sufficient quantity of causative organism. When a susceptible takes in an amount of infectious material, sufficient to induce infection, we say that the individual has made an infectious contact. Following the time of the infection, the newly infected individual generally passes through a latent period during which the infection develops purely internally, without the emission of any kind of infectious material. The latent period is the time from infection to onset of the ability to infect. It ends when the infected individual becomes infectious, and for the duration of the infectious period, we refer to the infected individual as an infective who can transmit infection to susceptibles. The infectious period ends when the infected individual ceases to be infectious, and he either becomes susceptible again or becomes a removal for some time. A removal is an individual who are immune or dead as a consequence of infection. A removal plays no part in the spread of the disease. The states of isolation and immunity may be temporary or permanent. Each infected individual is also referred to as a case. Figure 2.1: Chain of infection. Source: Centers for Disease Control and Prevention (Dicker and Gathany 1992). 2.2.3 Data visualization Data visualization or information visualization always played a crucial role in scientific analysis. In many infectious disease studies, data visualization could be a good starting point for the users to understand how far the disease will spread and to illustrate our findings and statistical insights. Besides, the ability to visualize, track, and predict the spread of the disease can help raise awareness, understand the impact of the disease, and ultimately assist in prevention efforts. Data visualization is having a big moment during the COVID-19 pandemic. Social media feeds are overwhelmed with infection heat maps and charts depicting transmission patterns. We have all seen models projecting the spread of the novel coronavirus. The COVID-19 pandemic also poses new challenges to data scientists, too, for its vast and rapid spread and significant economic impact. A lot of work has been done on visualizing COVID-19 data since the outbreak of the pandemic. The daily counts of cases and deaths of COVID-19 are crucial for understanding how this pandemic is spreading. Thanks to the contribution of the data science communities across the world, multiple sources provide the COVID-19 data with different precision and focus. To clean the data, we first fetch data from various sources and compile them into the same format for further comparison and integration. Appendix B describes the data used in the examples, case studies, and lab exercises in the book. R offers the opportunity to scale and automate tasks, document and track them, and reliably reproduce their output. The first few chapters investigate existing R visualization techniques used to manipulate and represent infectious disease data. Chapter 3 provides an introduction to data wrangling and how to use R packages dplyr and tidyr to manipulate your data in a useful form for visualization and modeling. This chapter is for someone who is already somewhat familiar with R, but would like to know more about using it for fundamental data analysis and manipulation. Figure 2.2: The stages of a data science workflow. Original source: Wickham and Grolemund (2016) Graphs can be presented using a variety of media: print, projection, dashboard, etc. The visualizations can be primarily classified into two groups: visualization with zero or less interactivity represents the first group, and complex interactive visualization techniques and tools represent the second. See Figure 2.3 for different types of visualization. Before constructing any display of epidemiologic data, it is important to first determine the point to be conveyed and which media you want to use for communications Figure 2.3: Types of visualization plots. Chapter 4 introduces static visualization, which uses basic graphs such as bar and line graphs for representing attributes of the COVID-19 dataset. We use a collection of graphs for comparing cumulative or daily new cases and deaths between states/counties in the US. Chapter 5 provide insight and practical skills for creating interactive and dynamic web graphics for data analysis from R. This kind of visualizations allow user interaction like hovering the mouse over bars and points in the charts. It makes heavy use of plotly for rendering graphics, but you’ll also learn about other R packages that augment a data science workflow, such as the tidyverse and shiny. Along the way, you’ll gain insight into best practices for visualization of infectious disease data, statistical graphics, and graphical perception. Chapter 6 focuses on linking plotly graphs with shiny, an open-source R package that provides an elegant and powerful web framework for building web applications. Chapter 7 is an in-depth look at visualizing data in a spatial setting and presenting findings through some geospatial visualization. 2.2.4 Modeling and Forecasting The concepts and techniques discussed in Chapters 3–6 have dealt with describing, visualizing, and exploring the data. The use of scientific models for understanding the dynamics of infectious diseases has a very rich history in epidemiology. Starting in December 2019 in China, the outbreak of COVID-19 has spread globally within weeks. To efficiently combat COVID-19, it is crucial to have a better understanding of how far the virus will spread, and how many lives it will claim. Scientific modeling is an essential tool to answer these questions and ultimately assist in disease prevention, policymaking, and resource allocation. Chapter 8 presents a few classic epidemic modeling approaches, and takes the reader through steps required for fundamental infectious data analysis and presentation of data typically encountered in epidemiology using COVID-19 data set. Chapter 9 introduces the analytical techniques of regression and discrimination as a means of quantifying the effect of a set of explanatory variables on the spatial distribution of a particular outcome. Chapter 10 takes the reader through time series modeling and forecasting. Chapter 11 introduces some neural network models for forecasting. Chapter 12 describes the ensemble methods using multiple forecasting algorithms to improve the predictive performance. References "],
["dplyr.html", "Chapter 3 Data Wrangling with dplyr and tidyr 3.1 Learning dplyr 3.2 Selecting Columns and Filtering Rows 3.3 Make New Variables: Mutate 3.4 Summarize Data 3.5 Combine Data Sets 3.6 Reshaping Data 3.7 Exercises", " Chapter 3 Data Wrangling with dplyr and tidyr The package dplyr is an R package for making tabular data wrangling easier by using a limited set of functions that can be combined to extract and summarize insights from your data. It pairs nicely with the package tidyr, enabling you to swiftly convert between different data formats (long vs. wide) for plotting and analysis. It addresses the common problem of reshaping your data for plotting and use by different R functions. Sometimes we want data sets where we have one row per measurement. Sometimes we want a dataframe where each measurement type has its own column, and rows are instead more aggregated groups. Sometimes you may want to select important variables, filter out key observations, create new variables and obtain summary statistics. As illustrated in Figure 3.1, you may need to work back and forth between these formats, which is nontrivial, and tidyr and dplyr give you the right tools for this and more sophisticated data wrangling. Figure 3.1: A typical data science process. The packages dplyr and tidyr are built to work directly with data frames. In this chapter, you will learn how to use these packages to perform data manipulation and transform your data into the appropriate form. 3.1 Learning dplyr # load the packages library(tidyverse) ## Warning: replacing previous import &#39;vctrs::data_frame&#39; by ## &#39;tibble::data_frame&#39; when loading &#39;dplyr&#39; ## ── Attaching packages ─────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.2.9000 ✓ purrr 0.3.4 ## ✓ tibble 3.0.4 ✓ dplyr 1.0.0 ## ✓ tidyr 1.1.0 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.5.0 ## ── Conflicts ────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(dplyr) 3.1.1 Tibbles Throughout this book, we work with “tibbles” instead of R’s traditional “data.frame”. Tibbles are data frames, but they are a modern reimagining of the “data.frame”, keeping what time has proven to be effective, and throwing out what is not. Here we will use the tibble package, which provides opinionated data frames that make working in the tidyverse a little easier. # The easiest way to get tibble is to install the whole tidyverse: install.packages(&quot;tidyverse&quot;) # Alternatively, install just tibble: install.packages(&quot;tibble&quot;) In most places, we will use the term “tibble” and “data frame” interchangeably; when we want to draw particular attention to R’s built-in data frame, we will call them “data.frame”. See Wickham and Grolemund (2016) for more details about how to create and use “tibbles”. 3.1.2 Import data Recall R offers many ways to import data: read_csv() reads comma delimited files, read_csv2() reads semicolon separated files. read_tsv() reads tab delimited files, and read_delim() reads in files with any delimiter. read_fwf() reads fixed width files. You can specify fields either by their widths with fwf_widths() or their position with fwf_positions(). read_table() reads a common variation of fixed width files where columns are separated by white space. load() loads an .RData file and import all of the objects contained in the .RData file into your current workspace. Below we will work on COVID-19 county level infected count data (I.county), and we can obtain the data from Github R package slid. It is a “data frame” which includes “ID” (county-level Federal Information Processing System code), “County” (name of county), “State” (name of state), “XYYYY.MM.DD” (the number of cumulative infected cases in a county related to the date of YYYY.MM.DD) for 3,104 counties in the US. For example, the variable X2020.01.22 is the number of cumulative infected cases in a county on 01/22/2020. See Appendix B for more detailed description of the data and its source. # install the slid package from github # library(devtools) # devtools::install_github(&#39;covid19-dashboard-us/slid&#39;) # load objects in I.county into my workspace library(slid) data(I.county) # make I.county a tibble with as_tibble() I.county &lt;- as_tibble(I.county) # preview the data # View(I.county) 3.1.3 Common dplyr functions Next, we will learn some of the most common dplyr functions: select(): subset columns; filter(): subset rows on conditions; mutate(): create new columns by using information from other columns; group_by() and summarize(): create summary statistics on grouped data; arrange(): sort results; join() family: combine datasets. A typical code structure of dplyr is: data.new &lt;- data.original %&gt;% select rows or columns to manipulate %&gt;% arrange or group the data %&gt;% summarize the data The first argument is a data frame, and the subsequent arguments separated by %&gt;% describe the data manipulation and/or summary, and the result is a new data frame. We will explain more details in the following sections. 3.2 Selecting Columns and Filtering Rows 3.2.1 Subset Variables (Columns) To select columns of a dataframe, use select(). The first argument to this function is the data frame (I.county), and the subsequent arguments are the columns to keep, separated by commas. Alternatively, if you are selecting columns adjacent to each other, you can use a : to select a range of columns, read as “select columns from __ to __”. # load the tidyverse dplyr::select(I.county, ID, County, State) # select a series of connected columns dplyr::select(I.county, ID, County, State, X2020.12.11:X2020.12.01) 3.2.2 Subset Observations (Rows) To choose rows based on specific criteria, we can use the filter() function. The arguments after the dataframe are the condition(s) we want for our final dataframe to adhere to (e.g. State name is “Iowa”). We can chain a series of conditions together using commas between each condition. # all Iowa counties dplyr::filter(I.county, State == &quot;Iowa&quot;) Here is an example of filter() function with multiple conditions: # all Iowa counties with cumulative infection count &gt; 10000 dplyr::filter(I.county, State == &quot;Iowa&quot;, X2020.12.11 &gt; 10000) To use filtering effectively, it is better to know some of the comparison and logical operators. Figure 3.2 shows some commonly used R logic comparisons: Figure 3.2: Some commonly used logic comparisons. 3.2.3 Pipes What if you want to select and filter at the same time? There are three ways to do this: use intermediate steps, nested functions, or pipes. With intermediate steps, you create a temporary dataframe and use that as input to the next function, like this: # all Iowa counties from 2020.12.01 to 2020.12.11 # method 1 Iowa.I.county &lt;- dplyr::filter(I.county, State == &quot;Iowa&quot;) Iowa.I.county.DEC &lt;- dplyr::select(Iowa.I.county, X2020.12.11:X2020.12.01) This is readable, but can clutter up your workspace with lots of objects that you have to name individually. With multiple steps, that can be hard to keep track of. You can also nest functions (i.e. one function inside of another), like this: # all Iowa counties from 2020.12.01 to 2020.12.11 # method 2 Iowa.I.county.DEC &lt;- dplyr::select(dplyr::filter(I.county, State == &quot;Iowa&quot;), ID, County, State, X2020.12.11:X2020.12.01) This is handy but can be difficult to read if too many functions are nested, as R evaluates the expression from the inside out (in this case, filtering, then selecting). The last option, pipes, are a recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. Pipes in R look like %&gt;% and are made available via the magrittr package, installed automatically with dplyr. # all Iowa counties from 2020.12.01 to 2020.12.11 # method 3 I.county %&gt;% dplyr::filter(State == &quot;Iowa&quot;) %&gt;% dplyr::select(ID, County, X2020.12.11:X2020.12.01) In the above code, we use the pipe to send the interviews dataset first through filter() to keep rows for the state of Iowa, then through select() to keep only the count in December. Since %&gt;% takes the object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include the dataframe as an argument to the filter() and select() functions anymore. Some may find it helpful to read the pipe like the word “then”. For instance, in the above example, we take the dataframe I.county, then we filter for rows with State == \"Iowa\", then we select columns from X2020.12.11 to X2020.12.01. The dplyr functions are somewhat simple, but by combining them into linear workflows with the pipe, we can accomplish more complex data wrangling operations. If we want to create a new object with this smaller version of the data, we can assign it a new name: # assign a name to all Iowa counties # from 2020.12.01 to 2020.12.11 Iowa.I.county.DEC &lt;- I.county %&gt;% dplyr::filter(State == &quot;Iowa&quot;) %&gt;% dplyr::select(ID, County, X2020.12.11:X2020.12.01) head(Iowa.I.county.DEC) ## # A tibble: 6 x 13 ## ID County X2020.12.11 X2020.12.10 X2020.12.09 ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 19001 Adair 506 503 499 ## 2 19003 Adams 208 206 200 ## 3 19005 Allam… 995 990 971 ## 4 19007 Appan… 868 862 858 ## 5 19009 Audub… 326 323 321 ## 6 19011 Benton 1852 1847 1826 ## # … with 8 more variables: X2020.12.08 &lt;int&gt;, ## # X2020.12.07 &lt;int&gt;, X2020.12.06 &lt;int&gt;, ## # X2020.12.05 &lt;int&gt;, X2020.12.04 &lt;int&gt;, ## # X2020.12.03 &lt;int&gt;, X2020.12.02 &lt;int&gt;, X2020.12.01 &lt;int&gt; 3.2.4 Select and order top n entries (by group if grouped data). The function top_n can be used to select top (or bottom) n rows (by value). This is a convenient wrapper that uses filter()and min_rank() to select the top or bottom entries in each group, ordered by wt. Usage top_n(x, n, wt) Arguments x: a tbl() to filter n: number of rows to return. If x is grouped, this is the number of rows per group. Will include more than n rows if there are ties. If n is positive, selects the top n rows. If negative, selects the bottom n rows. wt (Optional). The variable to use for ordering. If not specified, defaults to the last variable in the tbl. This argument is automatically quoted and later evaluated in the context of the data frame. It supports unquoting. Let us find the top ten counties with the largest cumulative infected count on December 11, 2020. # top ten counties with the cum. infected count I.county.top10 &lt;- I.county %&gt;% top_n(10, wt = X2020.12.11) I.county.top10$County ## [1] Maricopa LosAngeles SanBernardino Broward ## [5] Miami-Dade Cook Clark Dallas ## [9] Harris Tarrant ## 1839 Levels: Abbeville AcadiaParish Accomack Ada ... obrien Let us find the bottom ten counties with the smallest cumulative infected count on December 11, 2020. # bottom ten counties with the cum. infected count I.county.bottom10 &lt;- I.county %&gt;% top_n(-10, wt = X2020.12.11) I.county.bottom10$County ## [1] Dukes Nantucket OglalaLakota Beaver ## [5] BoxElder Cache Carbon Daggett ## [9] Duchesne Emery Garfield Grand ## [13] Iron Juab Kane Millard ## [17] Morgan Piute Rich Sanpete ## [21] Sevier Uintah Washington Wayne ## [25] Weber ## 1839 Levels: Abbeville AcadiaParish Accomack Ada ... obrien Let us find the county with the largest cumulative infected count on December 11, 2020 for each state. # county with the largest cum. infected count for each state I.county.top1 &lt;- I.county %&gt;% group_by(State) %&gt;% top_n(1, wt = X2020.12.11) %&gt;% dplyr::select(State, County) 3.3 Make New Variables: Mutate Frequently you will want to create new columns based on the values in existing columns, for example, to obtain the number of daily new cases based on the cumulative count. For this, we can use the mutate() function. # create a new variable Y2020.12.11 (new count 2020.12.11) I.county.new &lt;- I.county %&gt;% dplyr::filter(State == &quot;Iowa&quot;) %&gt;% dplyr::select(ID, County, X2020.12.11:X2020.12.10) %&gt;% mutate(Y2020.12.11 = X2020.12.11 - X2020.12.10) head(I.county.new) ## # A tibble: 6 x 5 ## ID County X2020.12.11 X2020.12.10 Y2020.12.11 ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 19001 Adair 506 503 3 ## 2 19003 Adams 208 206 2 ## 3 19005 Allamakee 995 990 5 ## 4 19007 Appanoose 868 862 6 ## 5 19009 Audubon 326 323 3 ## 6 19011 Benton 1852 1847 5 If we want to obtain the number of daily new cases based on the cumulative count for the dates in December only, we can try the following: # create variables Y2020.12.01 : Y2020.12.11 # with daily new count I.county.Iowa &lt;- I.county %&gt;% dplyr::filter(State == &quot;Iowa&quot;) I.county.tmp &lt;- I.county.Iowa[, -(1:3)] I.county.Iowa.new &lt;- I.county.Iowa I.county.Iowa.new[, -(1:3)] &lt;- I.county.tmp - cbind(I.county.tmp[, -1], 0) I.county.Iowa.DEC &lt;- I.county.Iowa.new %&gt;% dplyr::select(ID, County, X2020.12.11:X2020.12.01) name.tmp &lt;- substring(names(I.county.Iowa.DEC)[-(1:2)], 2) names(I.county.Iowa.DEC)[-(1:2)] &lt;- paste0(&quot;Y&quot;, name.tmp) head(I.county.Iowa.DEC) ## # A tibble: 6 x 13 ## ID County Y2020.12.11 Y2020.12.10 Y2020.12.09 ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 19001 Adair 3 4 10 ## 2 19003 Adams 2 6 4 ## 3 19005 Allam… 5 19 17 ## 4 19007 Appan… 6 4 5 ## 5 19009 Audub… 3 2 6 ## 6 19011 Benton 5 21 7 ## # … with 8 more variables: Y2020.12.08 &lt;int&gt;, ## # Y2020.12.07 &lt;int&gt;, Y2020.12.06 &lt;int&gt;, ## # Y2020.12.05 &lt;int&gt;, Y2020.12.04 &lt;int&gt;, ## # Y2020.12.03 &lt;int&gt;, Y2020.12.02 &lt;int&gt;, Y2020.12.01 &lt;int&gt; 3.4 Summarize Data Many data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy via the group_by() function. The summarize() function uses summary functions, functions that take a vector of values and return a single value, such as: dplyr::first: first value of a vector. dplyr::last: last value of a vector. dplyr::nth: nth value of a vector. dplyr::n: number of values in a vector. dplyr::n_distinct: number of distinct values in a vector. IQR: IQR of a vector. min: minimum value in a vector. max: maximum value in a vector. mean: mean value of a vector. median: median value of a vector. var: variance of a vector. sd: standard deviation of a vector. The group_by() function is often used together with summarize(), which collapses each group into a single-row summary of that group. The group_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics. Once the data are grouped, you can also summarize multiple variables simultaneously (and not necessarily on the same variable). So to compute the state level cumulative infected count by State: # state level cumulative infected count # method 1: summarize() I.state &lt;- I.county %&gt;% group_by(State) %&gt;% summarize(across(X2020.12.11:X2020.01.22, ~ sum(.x, na.rm = TRUE))) ## `summarise()` ungrouping output (override with `.groups` argument) head(I.state, 2) ## # A tibble: 2 x 326 ## State X2020.12.11 X2020.12.10 X2020.12.09 X2020.12.08 ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Alab… 288775 284922 280187 276665 ## 2 Ariz… 394512 387529 382601 378157 ## # … with 321 more variables: X2020.12.07 &lt;int&gt;, ## # X2020.12.06 &lt;int&gt;, X2020.12.05 &lt;int&gt;, ## # X2020.12.04 &lt;int&gt;, X2020.12.03 &lt;int&gt;, ## # X2020.12.02 &lt;int&gt;, X2020.12.01 &lt;int&gt;, ## # X2020.11.30 &lt;int&gt;, X2020.11.29 &lt;int&gt;, ## # X2020.11.28 &lt;int&gt;, X2020.11.27 &lt;int&gt;, ## # X2020.11.26 &lt;int&gt;, X2020.11.25 &lt;int&gt;, ## # X2020.11.24 &lt;int&gt;, X2020.11.23 &lt;int&gt;, ## # X2020.11.22 &lt;int&gt;, X2020.11.21 &lt;int&gt;, ## # X2020.11.20 &lt;int&gt;, X2020.11.19 &lt;int&gt;, ## # X2020.11.18 &lt;int&gt;, X2020.11.17 &lt;int&gt;, ## # X2020.11.16 &lt;int&gt;, X2020.11.15 &lt;int&gt;, ## # X2020.11.14 &lt;int&gt;, X2020.11.13 &lt;int&gt;, ## # X2020.11.12 &lt;int&gt;, X2020.11.11 &lt;int&gt;, ## # X2020.11.10 &lt;int&gt;, X2020.11.09 &lt;int&gt;, ## # X2020.11.08 &lt;int&gt;, X2020.11.07 &lt;int&gt;, ## # X2020.11.06 &lt;int&gt;, X2020.11.05 &lt;int&gt;, ## # X2020.11.04 &lt;int&gt;, X2020.11.03 &lt;int&gt;, ## # X2020.11.02 &lt;int&gt;, X2020.11.01 &lt;int&gt;, ## # X2020.10.31 &lt;int&gt;, X2020.10.30 &lt;int&gt;, ## # X2020.10.29 &lt;int&gt;, X2020.10.28 &lt;int&gt;, ## # X2020.10.27 &lt;int&gt;, X2020.10.26 &lt;int&gt;, ## # X2020.10.25 &lt;int&gt;, X2020.10.24 &lt;int&gt;, ## # X2020.10.23 &lt;int&gt;, X2020.10.22 &lt;int&gt;, ## # X2020.10.21 &lt;int&gt;, X2020.10.20 &lt;int&gt;, ## # X2020.10.19 &lt;int&gt;, X2020.10.18 &lt;int&gt;, ## # X2020.10.17 &lt;int&gt;, X2020.10.16 &lt;int&gt;, ## # X2020.10.15 &lt;int&gt;, X2020.10.14 &lt;int&gt;, ## # X2020.10.13 &lt;int&gt;, X2020.10.12 &lt;int&gt;, ## # X2020.10.11 &lt;int&gt;, X2020.10.10 &lt;int&gt;, ## # X2020.10.09 &lt;int&gt;, X2020.10.08 &lt;int&gt;, ## # X2020.10.07 &lt;int&gt;, X2020.10.06 &lt;int&gt;, ## # X2020.10.05 &lt;int&gt;, X2020.10.04 &lt;int&gt;, ## # X2020.10.03 &lt;int&gt;, X2020.10.02 &lt;int&gt;, ## # X2020.10.01 &lt;int&gt;, X2020.09.30 &lt;int&gt;, ## # X2020.09.29 &lt;int&gt;, X2020.09.28 &lt;int&gt;, ## # X2020.09.27 &lt;int&gt;, X2020.09.26 &lt;int&gt;, ## # X2020.09.25 &lt;int&gt;, X2020.09.24 &lt;int&gt;, ## # X2020.09.23 &lt;int&gt;, X2020.09.22 &lt;int&gt;, ## # X2020.09.21 &lt;int&gt;, X2020.09.20 &lt;int&gt;, ## # X2020.09.19 &lt;int&gt;, X2020.09.18 &lt;int&gt;, ## # X2020.09.17 &lt;int&gt;, X2020.09.16 &lt;int&gt;, ## # X2020.09.15 &lt;int&gt;, X2020.09.14 &lt;int&gt;, ## # X2020.09.13 &lt;int&gt;, X2020.09.12 &lt;int&gt;, ## # X2020.09.11 &lt;int&gt;, X2020.09.10 &lt;int&gt;, ## # X2020.09.09 &lt;int&gt;, X2020.09.08 &lt;int&gt;, ## # X2020.09.07 &lt;int&gt;, X2020.09.06 &lt;int&gt;, ## # X2020.09.05 &lt;int&gt;, X2020.09.04 &lt;int&gt;, ## # X2020.09.03 &lt;int&gt;, X2020.09.02 &lt;int&gt;, ## # X2020.09.01 &lt;int&gt;, X2020.08.31 &lt;int&gt;, ## # X2020.08.30 &lt;int&gt;, … or we can use summarize_at(), which affects variables selected with a character vector or vars(): # state level cumulative infected count # method 2: summarize_at() I.state &lt;- I.county %&gt;% group_by(State) %&gt;% summarize_at(vars(X2020.12.11:X2020.01.22), ~ sum(.x, na.rm = TRUE)) head(I.state, 2) ## # A tibble: 2 x 326 ## State X2020.12.11 X2020.12.10 X2020.12.09 X2020.12.08 ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Alab… 288775 284922 280187 276665 ## 2 Ariz… 394512 387529 382601 378157 ## # … with 321 more variables: X2020.12.07 &lt;int&gt;, ## # X2020.12.06 &lt;int&gt;, X2020.12.05 &lt;int&gt;, ## # X2020.12.04 &lt;int&gt;, X2020.12.03 &lt;int&gt;, ## # X2020.12.02 &lt;int&gt;, X2020.12.01 &lt;int&gt;, ## # X2020.11.30 &lt;int&gt;, X2020.11.29 &lt;int&gt;, ## # X2020.11.28 &lt;int&gt;, X2020.11.27 &lt;int&gt;, ## # X2020.11.26 &lt;int&gt;, X2020.11.25 &lt;int&gt;, ## # X2020.11.24 &lt;int&gt;, X2020.11.23 &lt;int&gt;, ## # X2020.11.22 &lt;int&gt;, X2020.11.21 &lt;int&gt;, ## # X2020.11.20 &lt;int&gt;, X2020.11.19 &lt;int&gt;, ## # X2020.11.18 &lt;int&gt;, X2020.11.17 &lt;int&gt;, ## # X2020.11.16 &lt;int&gt;, X2020.11.15 &lt;int&gt;, ## # X2020.11.14 &lt;int&gt;, X2020.11.13 &lt;int&gt;, ## # X2020.11.12 &lt;int&gt;, X2020.11.11 &lt;int&gt;, ## # X2020.11.10 &lt;int&gt;, X2020.11.09 &lt;int&gt;, ## # X2020.11.08 &lt;int&gt;, X2020.11.07 &lt;int&gt;, ## # X2020.11.06 &lt;int&gt;, X2020.11.05 &lt;int&gt;, ## # X2020.11.04 &lt;int&gt;, X2020.11.03 &lt;int&gt;, ## # X2020.11.02 &lt;int&gt;, X2020.11.01 &lt;int&gt;, ## # X2020.10.31 &lt;int&gt;, X2020.10.30 &lt;int&gt;, ## # X2020.10.29 &lt;int&gt;, X2020.10.28 &lt;int&gt;, ## # X2020.10.27 &lt;int&gt;, X2020.10.26 &lt;int&gt;, ## # X2020.10.25 &lt;int&gt;, X2020.10.24 &lt;int&gt;, ## # X2020.10.23 &lt;int&gt;, X2020.10.22 &lt;int&gt;, ## # X2020.10.21 &lt;int&gt;, X2020.10.20 &lt;int&gt;, ## # X2020.10.19 &lt;int&gt;, X2020.10.18 &lt;int&gt;, ## # X2020.10.17 &lt;int&gt;, X2020.10.16 &lt;int&gt;, ## # X2020.10.15 &lt;int&gt;, X2020.10.14 &lt;int&gt;, ## # X2020.10.13 &lt;int&gt;, X2020.10.12 &lt;int&gt;, ## # X2020.10.11 &lt;int&gt;, X2020.10.10 &lt;int&gt;, ## # X2020.10.09 &lt;int&gt;, X2020.10.08 &lt;int&gt;, ## # X2020.10.07 &lt;int&gt;, X2020.10.06 &lt;int&gt;, ## # X2020.10.05 &lt;int&gt;, X2020.10.04 &lt;int&gt;, ## # X2020.10.03 &lt;int&gt;, X2020.10.02 &lt;int&gt;, ## # X2020.10.01 &lt;int&gt;, X2020.09.30 &lt;int&gt;, ## # X2020.09.29 &lt;int&gt;, X2020.09.28 &lt;int&gt;, ## # X2020.09.27 &lt;int&gt;, X2020.09.26 &lt;int&gt;, ## # X2020.09.25 &lt;int&gt;, X2020.09.24 &lt;int&gt;, ## # X2020.09.23 &lt;int&gt;, X2020.09.22 &lt;int&gt;, ## # X2020.09.21 &lt;int&gt;, X2020.09.20 &lt;int&gt;, ## # X2020.09.19 &lt;int&gt;, X2020.09.18 &lt;int&gt;, ## # X2020.09.17 &lt;int&gt;, X2020.09.16 &lt;int&gt;, ## # X2020.09.15 &lt;int&gt;, X2020.09.14 &lt;int&gt;, ## # X2020.09.13 &lt;int&gt;, X2020.09.12 &lt;int&gt;, ## # X2020.09.11 &lt;int&gt;, X2020.09.10 &lt;int&gt;, ## # X2020.09.09 &lt;int&gt;, X2020.09.08 &lt;int&gt;, ## # X2020.09.07 &lt;int&gt;, X2020.09.06 &lt;int&gt;, ## # X2020.09.05 &lt;int&gt;, X2020.09.04 &lt;int&gt;, ## # X2020.09.03 &lt;int&gt;, X2020.09.02 &lt;int&gt;, ## # X2020.09.01 &lt;int&gt;, X2020.08.31 &lt;int&gt;, ## # X2020.08.30 &lt;int&gt;, … or we can use summarize_if(), which affects variables selected with a predicate function: # state level cumulative infected count # method 3: summarize_if() I.state &lt;- I.county %&gt;% group_by(State) %&gt;% summarize_if(is.numeric, ~ sum(.x, na.rm = TRUE)) head(I.state, 2) ## # A tibble: 2 x 327 ## State ID X2020.12.11 X2020.12.10 X2020.12.09 ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Alab… 71489 288775 284922 280187 ## 2 Ariz… 60208 394512 387529 382601 ## # … with 322 more variables: X2020.12.08 &lt;int&gt;, ## # X2020.12.07 &lt;int&gt;, X2020.12.06 &lt;int&gt;, ## # X2020.12.05 &lt;int&gt;, X2020.12.04 &lt;int&gt;, ## # X2020.12.03 &lt;int&gt;, X2020.12.02 &lt;int&gt;, ## # X2020.12.01 &lt;int&gt;, X2020.11.30 &lt;int&gt;, ## # X2020.11.29 &lt;int&gt;, X2020.11.28 &lt;int&gt;, ## # X2020.11.27 &lt;int&gt;, X2020.11.26 &lt;int&gt;, ## # X2020.11.25 &lt;int&gt;, X2020.11.24 &lt;int&gt;, ## # X2020.11.23 &lt;int&gt;, X2020.11.22 &lt;int&gt;, ## # X2020.11.21 &lt;int&gt;, X2020.11.20 &lt;int&gt;, ## # X2020.11.19 &lt;int&gt;, X2020.11.18 &lt;int&gt;, ## # X2020.11.17 &lt;int&gt;, X2020.11.16 &lt;int&gt;, ## # X2020.11.15 &lt;int&gt;, X2020.11.14 &lt;int&gt;, ## # X2020.11.13 &lt;int&gt;, X2020.11.12 &lt;int&gt;, ## # X2020.11.11 &lt;int&gt;, X2020.11.10 &lt;int&gt;, ## # X2020.11.09 &lt;int&gt;, X2020.11.08 &lt;int&gt;, ## # X2020.11.07 &lt;int&gt;, X2020.11.06 &lt;int&gt;, ## # X2020.11.05 &lt;int&gt;, X2020.11.04 &lt;int&gt;, ## # X2020.11.03 &lt;int&gt;, X2020.11.02 &lt;int&gt;, ## # X2020.11.01 &lt;int&gt;, X2020.10.31 &lt;int&gt;, ## # X2020.10.30 &lt;int&gt;, X2020.10.29 &lt;int&gt;, ## # X2020.10.28 &lt;int&gt;, X2020.10.27 &lt;int&gt;, ## # X2020.10.26 &lt;int&gt;, X2020.10.25 &lt;int&gt;, ## # X2020.10.24 &lt;int&gt;, X2020.10.23 &lt;int&gt;, ## # X2020.10.22 &lt;int&gt;, X2020.10.21 &lt;int&gt;, ## # X2020.10.20 &lt;int&gt;, X2020.10.19 &lt;int&gt;, ## # X2020.10.18 &lt;int&gt;, X2020.10.17 &lt;int&gt;, ## # X2020.10.16 &lt;int&gt;, X2020.10.15 &lt;int&gt;, ## # X2020.10.14 &lt;int&gt;, X2020.10.13 &lt;int&gt;, ## # X2020.10.12 &lt;int&gt;, X2020.10.11 &lt;int&gt;, ## # X2020.10.10 &lt;int&gt;, X2020.10.09 &lt;int&gt;, ## # X2020.10.08 &lt;int&gt;, X2020.10.07 &lt;int&gt;, ## # X2020.10.06 &lt;int&gt;, X2020.10.05 &lt;int&gt;, ## # X2020.10.04 &lt;int&gt;, X2020.10.03 &lt;int&gt;, ## # X2020.10.02 &lt;int&gt;, X2020.10.01 &lt;int&gt;, ## # X2020.09.30 &lt;int&gt;, X2020.09.29 &lt;int&gt;, ## # X2020.09.28 &lt;int&gt;, X2020.09.27 &lt;int&gt;, ## # X2020.09.26 &lt;int&gt;, X2020.09.25 &lt;int&gt;, ## # X2020.09.24 &lt;int&gt;, X2020.09.23 &lt;int&gt;, ## # X2020.09.22 &lt;int&gt;, X2020.09.21 &lt;int&gt;, ## # X2020.09.20 &lt;int&gt;, X2020.09.19 &lt;int&gt;, ## # X2020.09.18 &lt;int&gt;, X2020.09.17 &lt;int&gt;, ## # X2020.09.16 &lt;int&gt;, X2020.09.15 &lt;int&gt;, ## # X2020.09.14 &lt;int&gt;, X2020.09.13 &lt;int&gt;, ## # X2020.09.12 &lt;int&gt;, X2020.09.11 &lt;int&gt;, ## # X2020.09.10 &lt;int&gt;, X2020.09.09 &lt;int&gt;, ## # X2020.09.08 &lt;int&gt;, X2020.09.07 &lt;int&gt;, ## # X2020.09.06 &lt;int&gt;, X2020.09.05 &lt;int&gt;, ## # X2020.09.04 &lt;int&gt;, X2020.09.03 &lt;int&gt;, ## # X2020.09.02 &lt;int&gt;, X2020.09.01 &lt;int&gt;, ## # X2020.08.31 &lt;int&gt;, … It is sometimes useful to rearrange the result of a query to inspect the values. For instance, we can sort on X2020.12.11 to put the group with the largest cumulative infected count first using the arrange() function: # state level cumulative infected count # method 4: sort by the cum. infected count I.state &lt;- I.county %&gt;% group_by(State) %&gt;% summarize_if(is.numeric, ~ sum(.x, na.rm = TRUE)) %&gt;% arrange(desc(X2020.12.11)) head(I.state, 2) ## # A tibble: 2 x 327 ## State ID X2020.12.11 X2020.12.10 X2020.12.09 ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Cali… 3.51e5 1516215 1482551 1448987 ## 2 Texas 1.23e7 1388909 1374143 1359740 ## # … with 322 more variables: X2020.12.08 &lt;int&gt;, ## # X2020.12.07 &lt;int&gt;, X2020.12.06 &lt;int&gt;, ## # X2020.12.05 &lt;int&gt;, X2020.12.04 &lt;int&gt;, ## # X2020.12.03 &lt;int&gt;, X2020.12.02 &lt;int&gt;, ## # X2020.12.01 &lt;int&gt;, X2020.11.30 &lt;int&gt;, ## # X2020.11.29 &lt;int&gt;, X2020.11.28 &lt;int&gt;, ## # X2020.11.27 &lt;int&gt;, X2020.11.26 &lt;int&gt;, ## # X2020.11.25 &lt;int&gt;, X2020.11.24 &lt;int&gt;, ## # X2020.11.23 &lt;int&gt;, X2020.11.22 &lt;int&gt;, ## # X2020.11.21 &lt;int&gt;, X2020.11.20 &lt;int&gt;, ## # X2020.11.19 &lt;int&gt;, X2020.11.18 &lt;int&gt;, ## # X2020.11.17 &lt;int&gt;, X2020.11.16 &lt;int&gt;, ## # X2020.11.15 &lt;int&gt;, X2020.11.14 &lt;int&gt;, ## # X2020.11.13 &lt;int&gt;, X2020.11.12 &lt;int&gt;, ## # X2020.11.11 &lt;int&gt;, X2020.11.10 &lt;int&gt;, ## # X2020.11.09 &lt;int&gt;, X2020.11.08 &lt;int&gt;, ## # X2020.11.07 &lt;int&gt;, X2020.11.06 &lt;int&gt;, ## # X2020.11.05 &lt;int&gt;, X2020.11.04 &lt;int&gt;, ## # X2020.11.03 &lt;int&gt;, X2020.11.02 &lt;int&gt;, ## # X2020.11.01 &lt;int&gt;, X2020.10.31 &lt;int&gt;, ## # X2020.10.30 &lt;int&gt;, X2020.10.29 &lt;int&gt;, ## # X2020.10.28 &lt;int&gt;, X2020.10.27 &lt;int&gt;, ## # X2020.10.26 &lt;int&gt;, X2020.10.25 &lt;int&gt;, ## # X2020.10.24 &lt;int&gt;, X2020.10.23 &lt;int&gt;, ## # X2020.10.22 &lt;int&gt;, X2020.10.21 &lt;int&gt;, ## # X2020.10.20 &lt;int&gt;, X2020.10.19 &lt;int&gt;, ## # X2020.10.18 &lt;int&gt;, X2020.10.17 &lt;int&gt;, ## # X2020.10.16 &lt;int&gt;, X2020.10.15 &lt;int&gt;, ## # X2020.10.14 &lt;int&gt;, X2020.10.13 &lt;int&gt;, ## # X2020.10.12 &lt;int&gt;, X2020.10.11 &lt;int&gt;, ## # X2020.10.10 &lt;int&gt;, X2020.10.09 &lt;int&gt;, ## # X2020.10.08 &lt;int&gt;, X2020.10.07 &lt;int&gt;, ## # X2020.10.06 &lt;int&gt;, X2020.10.05 &lt;int&gt;, ## # X2020.10.04 &lt;int&gt;, X2020.10.03 &lt;int&gt;, ## # X2020.10.02 &lt;int&gt;, X2020.10.01 &lt;int&gt;, ## # X2020.09.30 &lt;int&gt;, X2020.09.29 &lt;int&gt;, ## # X2020.09.28 &lt;int&gt;, X2020.09.27 &lt;int&gt;, ## # X2020.09.26 &lt;int&gt;, X2020.09.25 &lt;int&gt;, ## # X2020.09.24 &lt;int&gt;, X2020.09.23 &lt;int&gt;, ## # X2020.09.22 &lt;int&gt;, X2020.09.21 &lt;int&gt;, ## # X2020.09.20 &lt;int&gt;, X2020.09.19 &lt;int&gt;, ## # X2020.09.18 &lt;int&gt;, X2020.09.17 &lt;int&gt;, ## # X2020.09.16 &lt;int&gt;, X2020.09.15 &lt;int&gt;, ## # X2020.09.14 &lt;int&gt;, X2020.09.13 &lt;int&gt;, ## # X2020.09.12 &lt;int&gt;, X2020.09.11 &lt;int&gt;, ## # X2020.09.10 &lt;int&gt;, X2020.09.09 &lt;int&gt;, ## # X2020.09.08 &lt;int&gt;, X2020.09.07 &lt;int&gt;, ## # X2020.09.06 &lt;int&gt;, X2020.09.05 &lt;int&gt;, ## # X2020.09.04 &lt;int&gt;, X2020.09.03 &lt;int&gt;, ## # X2020.09.02 &lt;int&gt;, X2020.09.01 &lt;int&gt;, ## # X2020.08.31 &lt;int&gt;, … In the above, desc() is used to re-oorder by a column in descending order. 3.5 Combine Data Sets R has a number of quick, elegant ways to join data frames by a common column. There are at least three ways: Base R’s merge() function, Join family of functions from dplyr, and Bracket syntax based on data.table. 3.5.1 The join family The dplyr uses SQL database syntax for its join functions. For example, a left join means: Include everything on the left and all rows that match from the right data frame. If the join columns have the same name, all you need is left_join(x, y). If they don’t have the same name, you need a by argument, such as left_join(x, y, by = c(\"df1ColName\" = \"df2ColName\")). See an illustration in Figure 3.3. Figure 3.3: An illustration of left join and right join. Different join functions control what happens to rows that exist in one table but not the other. left_join keeps all the entries that are present in the left (first) table and excludes any that are only in the right table. right_join keeps all the entries that are present in the right table and excludes any that are only in the left table. inner_join keeps only the entries that are present in both tables. inner_join is the only function that guarantees you won’t generate any missing entries. full_join keeps all of the entries in both tables, regardless of whether or not they appear in the other table. Figure 3.4: An illustration of inner join and full join. The join functions are nicely illustrated in RStudio’s Data wrangling cheatsheet. Figure 3.5: An illustration of the join functions in RStudio’s Data wrangling cheatsheet. 3.5.2 Toy examples with joins a &lt;- tibble(x1 = LETTERS[c(1:3)], x2 = 1:3) b &lt;- tibble(x1 = LETTERS[c(1, 2, 4)], x3 = c(T, F, T)) a ## # A tibble: 3 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 b ## # A tibble: 3 x 2 ## x1 x3 ## &lt;chr&gt; &lt;lgl&gt; ## 1 A TRUE ## 2 B FALSE ## 3 D TRUE # include all rows in a and b inner_join(a, b, by = &quot;x1&quot;) ## # A tibble: 2 x 3 ## x1 x2 x3 ## &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; ## 1 A 1 TRUE ## 2 B 2 FALSE # return all rows from a left_join(a, b, by = &quot;x1&quot;) ## # A tibble: 3 x 3 ## x1 x2 x3 ## &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; ## 1 A 1 TRUE ## 2 B 2 FALSE ## 3 C 3 NA # return all rows from b right_join(a, b, by = &quot;x1&quot;) ## # A tibble: 3 x 3 ## x1 x2 x3 ## &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; ## 1 A 1 TRUE ## 2 B 2 FALSE ## 3 D NA TRUE # includes all rows in a or b full_join(a, b, by = &quot;x1&quot;) ## # A tibble: 4 x 3 ## x1 x2 x3 ## &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; ## 1 A 1 TRUE ## 2 B 2 FALSE ## 3 C 3 NA ## 4 D NA TRUE # include the rows in a that are not in b anti_join(a, b, by = &quot;x1&quot;) ## # A tibble: 1 x 2 ## x1 x2 ## &lt;chr&gt; &lt;int&gt; ## 1 C 3 # want everything that doesn&#39;t match? full_join(anti_join(a, b, by = &quot;x1&quot;), anti_join(b, a, by = &quot;x1&quot;), by = &quot;x1&quot;) ## # A tibble: 2 x 3 ## x1 x2 x3 ## &lt;chr&gt; &lt;int&gt; &lt;lgl&gt; ## 1 C 3 NA ## 2 D NA TRUE 3.5.3 Practice with joins for real data Example 1 We first get the data named pop.county from the github R package slid. Note that there are four variables in this data: “ID” (county-level Federal Information Processing System code), “County” (name of county matched with “ID”), “State” (name of state matched with “ID”), population (population of county matched with “ID”). data(I.county) data(pop.county) # make I.county a tibble with as_tibble() I.county &lt;- as_tibble(I.county) dim(I.county) ## [1] 3104 328 # make pop.county a tibble with as_tibble() pop.county &lt;- as_tibble(pop.county) dim(pop.county) ## [1] 3142 4 Now, we would like to join the two tables: I.county and pop.county using the left_join as follows: pop.county.tmp &lt;- pop.county %&gt;% dplyr::select(-c(County, State)) I.county.w.pop &lt;- left_join(I.county, pop.county.tmp, by = &quot;ID&quot;) or we can: I.county.w.pop &lt;- left_join(I.county, dplyr::select(pop.county, c(ID, population)), by = &quot;ID&quot;) Example 2 In this example, we would like to create a map to show the risk of COVID-19 infection in each state of the US. So, first, we need to have a new dataset that contains infection risk and the geographic information of each state. We will get infected count and state population in the state.long dataset in the slid package. state.long is a tibble with 15,925 rows and 7 columns. Next, we obtain the boundary information of each state downloaded from PublicaMundi. Then, we merge the two datasets to create a new dataset. We need the R package geojsonio to read the data from PublicaMundi. library(geojsonio) ## ## Attaching package: &#39;geojsonio&#39; ## The following object is masked from &#39;package:base&#39;: ## ## pretty library(slid) data(state.long) # get the geospatial information from PublicaMundi states0 &lt;- geojson_read( x = &quot;https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json&quot; , what = &quot;sp&quot; ) head(states0@data) ## id name density ## 1 01 Alabama 94.650 ## 2 02 Alaska 1.264 ## 3 04 Arizona 57.050 ## 4 05 Arkansas 56.430 ## 5 06 California 241.700 ## 6 08 Colorado 49.330 states1 &lt;- states0 states1@data &lt;- states0@data %&gt;% # remove the space in the name of state if there is one mutate(name_ns = sapply(name, gsub, pattern = &quot; &quot;, replacement = &quot;&quot;)) # the following merge step can be done both using sp::merge # or the join functions in dplyr # states1 &lt;- sp::merge(states1, state.long %&gt;% # filter(DATE == as.Date(&#39;2020-12-11&#39;)), # by.x = &quot;name_ns&quot;, by.y = &quot;State&quot;) # merge the two datasets states1@data &lt;- left_join(states1@data, state.long %&gt;% filter(DATE == as.Date(&#39;2020-12-11&#39;)), by = c(&#39;name_ns&#39; = &#39;State&#39;)) # calculate the risk of infection states1@data &lt;- states1@data %&gt;% mutate(Infect_risk = Infected / pop) 3.6 Reshaping Data Sometimes, we want to convert data from a wide format to a long format. Many functions in R expect data to be in a long format rather than a wide format. Programs like SPSS, however, often use wide-formatted data. Take the dataset I.state for example, the column names “XYYYY.MM.DD” are not names of variables, but values of a variable, which contains the values of cumulative infected count. We need to pivot the column names into new variables. There are two sets of methods that are explained below: gather() and spread() from the tidyr package. This is a newer interface to the reshape2 package. pivot_longer and pivot_wider from the tidyr package. Many other methods aren’t covered here since they are not as easy to use. 3.6.1 From wide to long Below we would like to change the data I.state from wide format to long format. library(slid) data(I.state) names(I.state) Use gather(data, key, value, ...) data = the dataframe you want to morph from wide to long key = the name of the new column that is levels of what is represented in the wide format as many columns value = the name of the column that will contain the values ... = columns to gather, or leave (use -column to gather all except that one) The gather functions are nicely illustrated in RStudio’s [Data wrangling cheatsheet][https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf] as shown in Figure 3.6. Figure 3.6: An illustration of gather function. # method 1 I.state.wide &lt;- I.state dim(I.state.wide) ## [1] 49 326 I.state.long &lt;- gather(I.state.wide, DATE, Infected, X2020.12.11:X2020.01.22, factor_key = TRUE) %&gt;% arrange(State) dim(I.state.long) ## [1] 15925 3 Use pivot_longer() The function pivot_longer() is an updated approach to gather(), designed to be both simpler to use and to handle more use cases. It is recommended to use pivot_longer() for new code; gather() isn’t going away but is no longer under active development. # method 2 I.state.wide &lt;- I.state dim(I.state.wide) ## [1] 49 326 I.state.long &lt;- I.state.wide %&gt;% pivot_longer(X2020.12.11:X2020.01.22, names_to = &quot;DATE&quot;, values_to = &quot;Infected&quot;) See more complicated examples from the introduction of ‘tidyr’ package. 3.6.2 From long to wide Now let’s change the data back to the wide format, and we can use spread. Use Use spread(data, key, value) data = the dataframe you want to morph from long to wide key = the name of the column that contains the key value = the name of the column contains the values The spread functions are nicely illustrated in RStudio’s [Data wrangling cheatsheet][https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf] as shown in Figure 3.7. Figure 3.7: An illustration of spread function. # method 1 I.state.wide &lt;- spread(I.state.long, DATE, Infected) dim(I.state.wide) ## [1] 49 326 Use pivot_wider() We can also use the function pivot_wider(), which “widens” data, increasing the number of columns and decreasing the number of rows. The inverse transformation is pivot_longer(). # method 2 I.state.wide &lt;- I.state.long %&gt;% pivot_wider(names_from = DATE, values_from = Infected) dim(I.state.wide) ## [1] 49 326 See more complicated examples from the introduction of ‘tidyr’ package. 3.7 Exercises We are going to explore the basic data manipulation verbs of dplyr using I.county. Install the github R package slid. library(slid) data(I.county) Obtain a subset of the I.county by selecting ID, County, State. Obtain a subset of the I.county by including all counties in California. Obtain a subset of the I.county by including all counties that in the midwest states. Midwest = c( &quot;Illinois&quot;, &quot;Michigan&quot;, &quot;Indiana&quot; ,&quot;Ohio&quot;, &quot;Wisconsin&quot;, &quot;Iowa&quot;, &quot;Kansas&quot;, &quot;Minnesota&quot;, &quot;Missouri&quot;, &quot;Nebraska&quot; , &quot;SouthDakota&quot; , &quot;NorthDakota&quot;) Obtain a subset of the I.county by including the top ten counties from each midwest state based on the cumulative infected count on December 11, 2020. Obtain a subset of the I.county by including all the counties California with the culumative infected counts up till Judy 31, 2020. Create new columns of I.county by taking the logarithm of each of the count column. Sort the cumulative infected count on December 11, 2020 to find the state with the largest cumulative infected count. Downlad the data pop.county from the github R package slid. Join the tables of I.county and pop.county using inner_join, left_join , right_join, full_join. Do you get same or different tables? Based on the inner_join create a table and name it as I.pop.county, then create new columns of I.pop.county by dividing each of the count column by the popolation in the corresponding county, for example, risk.2020.12.11 = X.2020.12.11 / pop. For each state, list the top ten county with the highest risk based on risk.2020.12.11 References "],
["ggplot2.html", "Chapter 4 Data Visualization with ggplot2 4.1 Introduction 4.2 Types of Variables and Preparation 4.3 Position Scales and Axes 4.4 Color Scales and Size of geom_points() 4.5 Individual geoms 4.6 Collective geoms 4.7 Time Series 4.8 Maps 4.9 Arranging Plots 4.10 Output 4.11 Exercises", " Chapter 4 Data Visualization with ggplot2 4.1 Introduction The first thing to do in the epidemiologic data analysis task is to plot the data. Data visualization enables many features of the data to be displayed or summarized in a graphical format, including patterns, unusual observations, changes over time, spatial variations, and relationships among variables. The features that are seen in graphs of the data must then be incorporated, as much as possible, into the modeling or forecasting methods. There are many types of graphs available, each with its own strengths and use cases. One of the challenges in the statistical learning process is choosing the appropriate visualization method to represent the data. Before constructing any display of epidemiologic data, it is important to understand the type of task that we want to perform and determine the information to convey. Some common roles for data visualization include: highlighting a change from past patterns in the data; displaying a part-to-whole composition; showing how data is distributed; showing a difference or similarity between groups; displaying the spatial variation in geographical data; illustrating relationships among variables. When the data are more complex, graphs can help visualize broader patterns and trends and identify variations from those trends. Variations in data may represent important new findings or only errors in typing or coding which need to be corrected. Thus, graphs can be helpful tools to aid in verifying and analyzing the data. Once an analysis is complete, graphs further serve as useful visual aids for describing the data to others. This chapter will introduce the ggplot2, and we will gain insight and practical skills for visualization of infectious disease data. Recommended Reading: https://ggplot2.tidyverse.org https://opr.princeton.edu/workshops/Downloads/ https://ggplot2-book.org/introduction.html ggplot2 builds on Leland Wilkinson’s The Grammar of Graphics and focuses on the primacy of layers and adapts it for R. In brief, the grammar tells us that a graphic maps the data to the aesthetic attributes (color, shape, size) of geometric objects (points, lines, bars). The plot may also include statistical transformations of the data and information about the plot’s coordinate system. Facetting can be used to plot for different subsets of the data. The combination of these independent components is what makes up a graphic. In this chapter, we will introduce the basics of ggplot2 grammar and some of the key features, including the use of geom, stat, scale, coord, and facet. 4.2 Types of Variables and Preparation When preparing graphs, keep in mind that the primary purpose is to communicate information. The types of variables we are analyzing and the media for the visualization can also affect your graphics practice. 4.2.1 Types of Variables In examining data, you must know which data type you are dealing with to choose the appropriate display format. The data are ususally in one of the following categories: Categorical (Qualitative) variables A nominal variable is one whose values are categories without any numerical ranking. Good examples are occupation, place of birth, county of residence and diagnosis. Nominal variable is called dichotomous when it is characterised by only two classes. In epidemiology, it is common to see dichotomous variables: sex (male/female), exposure history (yes/no), alive or dead, ill or well, vaccinated or unvaccinated. An ordinale variable has values that can be ranked but are not necessarily evenly spaced. For example, severity of illness may be categorised and ordered as “mild”, “moderate” or “severe”. Numerical (Quantitative) variables There are two types of quantitative variables: Discrete variables have values that are distinct and separate. Discrete data can’t be measured but can be counted. For example, the number of new cases of a certain disease in a given year. Continuous variables represents measurements and can have any value in a range. Examples of continuous data would be the amount of the time period between when you catch a virus and when your symptoms start. Discrete data can’t be counted but can be measured. An interval-scale variable is measured on a scale of equally spaced units, but without a true zero point. An example of interval data is date of birth. A ratio-scale variable is the same as interval values, with the difference that they do have an absolute zero. Good examples are be height in centimeters or duration of illness. 4.2.2 Rules for Graph Designing When designing graphs, we need to follow some rules to achieve the best practices, and Dicker and Gathany (1992) suggests the following: Ensure that a graphic can stand alone by clear labeling of title, source, axes, scales, and legends; Clearly identify variables portrayed (legends or keys), including units of measure; Minimize number of lines on a graph; Generally, portray frequency on the vertical scale, starting at zero, and classification variable on horizontal scale; Ensure that scales for each axis are appropriate for data presented; Define any abbreviations or symbols; and Specify any data excluded. 4.2.3 Installing packages and loading data Before we begin, please get ready by installing the ggplot2 package by any of the following method. # The easiest way to get ggplot2 is to install the whole tidyverse: install.packages(&quot;tidyverse&quot;) # Alternatively, install just ggplot2: install.packages(&quot;ggplot2&quot;) # Or the development version from GitHub: # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;tidyverse/ggplot2&quot;) Note: devtools downloads and installs the package from GitHub. By default, install.packages() is only able to install packages that are available in Comprehensive R Archive Network (CRAN). In that case, the developer’s tool, devtools::install_github() enables users to install packages that have not been submitted to CRAN, but is available in GitHub. In addition, we need to library the required packages as following. In the rest of this section, we demonstrate how to create a basic scatter plot and output the figure in “png” and “rds” format. To create a ggplot2 plot, we need to know three key components: (1) A dataframe with each column being an attribute/variable, each row being an individual; (2) A set of aesthetic mappings between variables in the data and visual properties, and (3) At least one layer which describes how to render each observation. Layers are usually created with a geom function. “ggplot” generally likes data in the “long” format: i.e., a column for every dimension, and a row for every observation. For illustration, we are going to use the state.long dataset in the R package slid. To prepare the data, install the R package slid from Github using the following command, which includes the datasets that we use for this book. Open the state.long dataset, which includes the variables, cumulative infected cases (Infected), cumulative death counts (Death), Region, Division, State, population (pop), and DATE, starting from Jan 22, 2020. Take a look at the first few lines using head(). df &lt;- slid::state.long head(df) ## # A tibble: 6 x 7 ## State Region Division pop DATE Infected Death ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; ## 1 Alaba… South East South… 4.89e6 2020-12-11 288775 4086 ## 2 Alaba… South East South… 4.89e6 2020-12-10 284922 4034 ## 3 Alaba… South East South… 4.89e6 2020-12-09 280187 3985 ## 4 Alaba… South East South… 4.89e6 2020-12-08 276665 3940 ## 5 Alaba… South East South… 4.89e6 2020-12-07 272228 3891 ## 6 Alaba… South East South… 4.89e6 2020-12-06 269877 3888 4.2.4 Your first scatterplot Here we introduce how to draw a simple scatter plot using the data of ‘2020-12-11’. Treat log(Infected) as the x-axis, and log(Death) as the y-axis. We create it by telling “ggplot” the data df, the aesthetic mapping aes(log(Infected), log(Death)), and the layer geom_point(). The structure ggplot() + geom_point() is the typical way to create a plot, in which “ggplot” is told the data and mapping, and geom_point is a layer of a picture using the information embedded in “ggplot”. Later in this chapter, you will see how we can use + to assign additional adjustments and add multiple layers to the existing figure. # Select the date df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) # Create scatter plot # Data: df # Aesthetic: first mapped to x, second mapped to y # Layer: render the plot as a scatterplot p &lt;- ggplot(df, aes(log(Infected + 1), log(Death + 1))) p + geom_point() Figure 4.1: Scatterplot of log cumulative death against log cumulative infected Remarks: In the above example, the dataframe df is the first parameter in the above ggplot(), and aesthetics are defined within an aes() function. We need to place + at the end of the previous line instead of the beginning of new line. Aesthetics are properties of the plot that can show certain elements of the data. The following is a list of some common plot aesthetics you might want to specify in your geom_point(): x: position on x-axis y: position on y-axis alpha: transparency (1: opaque; 0: transparent) color: color of border of elements fill: color of inside of elements shape: shape group: group size: size stroke: border size of points We will explain more details in the following sections. 4.3 Position Scales and Axes 4.3.1 Change the labels of the axis using xlab() and ylab() See Figure 4.2 for the customized labels and title. # Change the transparency using alpha p &lt;- p + geom_point(alpha = 0.7) + # Change the label of horizontal axis xlab(&#39;log Infected&#39;) + # Change the label of vertical axis ylab(&#39;log Death&#39;) + # Change the title labs(title = &#39;Log death against infected cases in US&#39;) p Figure 4.2: Scatterplot with customized lables and title #p + scale_x_reverse() #p + scale_y_reverse() 4.3.2 Change the range of the axis using xlim() and ylim() For continuous variables, we can provide the lower and upper limits. For categorical variables, we can provide the names of categories desired. To suppress the warning “Removed XXX rows containing missing values”, use na.rm. This needs to be carefully used because the data outside the range are converted to NA, which will affect later manipulations, such as calculating the mean or sum. # For continuous variable, provide the lower and upper limits p &lt;- p + geom_point() + ylim(4, 12) p Figure 4.3: Scatterplot with customized axis range for continuous features # For discrete variable, provide the names of categories desired # To suppress the warning &#39;Removed XXX rows containing...&#39;, use `na.rm`. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) ggplot(df, aes(Region, log(Death + 1))) + geom_point(na.rm = TRUE) + xlim(&#39;West&#39;, &#39;Midwest&#39;, &#39;South&#39;) Figure 4.4: Scatterplot with customized axis range for discrete features 4.4 Color Scales and Size of geom_points() There are two ways of coloring. One approach is to color all points with the same color. The other method is to color the points according to a particular feature of the observation. 4.4.1 Change the color of all points p + geom_point(color = &quot;blue&quot;) Figure 4.5: Scatterplot with all points colored blue 4.4.2 Color the observations by the value of a feature # Use Region as the feature for coloring p + geom_point(aes(color = Region)) # p + aes(color = Region) # Use population for coloring p + geom_point(aes(color = pop)) Figure 4.6: Scatterplot with points colored by Region or Population Remarks: the color feature is located at different layers in three figures. In the first figure, it is under geom_point(), while in the latter two figures it is under geom_point(aes()). Because we only have one layer in this example, we can equivalently use aes(), i.e., the aesthetic mapping for the whole scatterplot. 4.4.3 Change the color palette In addition, we can personalize the color palette using scale_fill_brewer() for a discrete color scale, and scale_fill_distiller() for a continuous color scale. # Change the palette # For discrete scale p + geom_point(aes(color = Region)) + scale_fill_brewer(palette = &quot;Set1&quot;, aesthetics = &quot;color&quot;) # For continuous scale p + geom_point(aes(color = pop)) + scale_fill_distiller(palette = 2, aesthetics = &quot;color&quot;) Figure 4.7: Scatterplot with customized color palette 4.4.4 Change the size by the value of a feature p &lt;- ggplot(df, aes(log(Infected + 1), log(Death + 1))) + xlab(&#39;log Infected&#39;) + ylab(&#39;log Death&#39;) + labs(title = &#39;Log death against infected cases in US&#39;) # Change the point size p + geom_point(aes (size = pop)) # Change the point color and size p + geom_point(aes (size = pop , color = pop)) Figure 4.8: Scatterplot with customized point size or color # Combine the color and size in legend # Method 1: keep the size and color the same limits and breaks p + geom_point(aes (size = pop, color = pop)) + scale_color_continuous(limits = c(0e7, 4e7), breaks = seq(0, 4e7, by = 1e7)) + scale_size_area(limits = c(0e7, 4e7), breaks = seq(0, 4e7, by = 1e7), max_size = 12) + guides(color = guide_legend(), size = guide_legend()) # Method 2: use scale_color_gradient and scale_size p &lt;- p + geom_point(aes(size = pop, color = pop), alpha = 0.7) + scale_color_gradient(low = &quot;lightblue&quot;, high = &quot;red&quot;) + scale_size_area(max_size = 12) + guides(color = guide_legend(), size = guide_legend()) p Figure 4.9: Scatterplot with customized point color and point size Remarks: For Method 1, the key to combining two aesthetic settings of the layer to one legend, in this case, color and size, is to set the limits and breaks to be the same in guides. For both methods, guides(color = guide_legend(), size = guide_legend()) is needed. 4.5 Individual geoms Apart from the scatter plot, there are many individual geoms, for example: geom_line(): line graphs geom_boxplot():boxplots geom_bar(): bar chart geom_histogram(): histogram plots geom_smooth(): regression lines or curves We introduce a few of them in detail as follows. 4.5.1 Histogram The histogram is an important tool to summarize the range and frequency of observations. Here we plot the histogram of log daily new infected cases counts using using geom_histogram. We can adjust the option binwidth to control the widths of the bins. # Prepare the daily new Infected for each state # in the period 2020-11-12 to 2020-12-11 df &lt;- slid::state.long %&gt;% dplyr::filter(DATE &lt;= &#39;2020-12-11&#39; &amp; DATE &gt; &#39;2020-11-11&#39;) %&gt;% group_by(State) %&gt;% # Group by State mutate(Y.Infected = c(Infected[-length(Infected)] - Infected[-1], 0)) df ## # A tibble: 1,470 x 8 ## # Groups: State [49] ## State Region Division pop DATE Infected Death ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; ## 1 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 2 Alab… South East So… 4.89e6 2020-12-10 284922 4034 ## 3 Alab… South East So… 4.89e6 2020-12-09 280187 3985 ## 4 Alab… South East So… 4.89e6 2020-12-08 276665 3940 ## 5 Alab… South East So… 4.89e6 2020-12-07 272228 3891 ## 6 Alab… South East So… 4.89e6 2020-12-06 269877 3888 ## 7 Alab… South East So… 4.89e6 2020-12-05 267589 3876 ## 8 Alab… South East So… 4.89e6 2020-12-04 264199 3831 ## 9 Alab… South East So… 4.89e6 2020-12-03 260359 3776 ## 10 Alab… South East So… 4.89e6 2020-12-02 256828 3711 ## # … with 1,460 more rows, and 1 more variable: ## # Y.Infected &lt;dbl&gt; p &lt;- ggplot(df, aes(log(Y.Infected + 1))) p + geom_histogram(binwidth = 1) p + geom_histogram(binwidth = 1) + aes(fill = Region) Figure 4.10: Histogram examples 4.5.2 Bar chart The discrete analogue of histogram is the bar chart. 4.5.3 Default bar chart The default geom_bar(), or equivalently geom_bar(stat='count'), counts the number of observations in each category shown as following. This plot essentially tells us how many states there are in each region. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) p &lt;- ggplot(df, aes(Region)) p + geom_bar() Figure 4.11: Bar plot example 4.5.4 Bar chart with assigned value In addition to the previous example, we can assign the height of the bars by ourselves by using the option geom_bar(stat = 'identity'). In that case, we tell geom_bar to use y value in the data frame as the height of the bars. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) p &lt;- ggplot(df, aes(Region, Infected)) p + geom_bar(stat = &#39;identity&#39;) p + geom_bar(stat = &#39;identity&#39;, aes(fill = Division)) Figure 4.12: Bar plot with assigned values 4.5.5 Legend Legend position We can adjust the position of the legends using theme(legend.position = 'left/right/bottom/none'). p &lt;- ggplot(df, aes(Region, fill = Region)) + ylab(&#39;Number of states&#39;) + geom_bar() p + theme(legend.position = &#39;bottom&#39;) Figure 4.13: Scatterplot with legend at bottom Legend guide guide_legend() We can also assign individual keys to the legend using options of guide_legend(). Here we introduce the most useful options. nrow and ncol: specify the dimensions of the table. byrow: fills the rows, set to FALSE by default. p + guides(fill = guide_legend(ncol = 2, byrow = TRUE)) Figure 4.14: Bar plots of number of states in each region reverse: reverse the order of the keys p + guides(fill = guide_legend(reverse = TRUE)) Figure 4.15: Bar plots of number of states in each region 4.5.6 Boxplots, jittering and violin plots Conditioning on a categorical feature, or conditioning on groups, we may want to conduct a side-by-side comparison for a certain variable. We can use the following tools. Jittering, geom_jitter(), adds a little random noise to the data, which can help avoid overplotting. Boxplots, geom_boxplot(), summarize the shape of the distribution with a handful of summary statistics. Violin plots, geom_violin(), show a compact representation of the “density” of the distribution, highlighting the areas where more points are found. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) %&gt;% mutate(Risk = Infected / pop) p &lt;- ggplot(df, aes(Region, Risk, color = Region)) p + geom_point() p + geom_jitter() p + geom_boxplot() p + geom_violin() Figure 4.16: Points, jittering, boxplot, and violin plot examples 4.6 Collective geoms An individual “geom” draws a distinct graphical object for each observation (row). For example, the “point geom” draws one point per row. Several geoms can be added to the same ggplot object, which allows you to build up layers to create complex graphs and displays multiple observations with one geometric object. For example, we previously have created a scatter plot, and we can add regressed lines on the top of the scatter plot layer. You can add more information from a statistical summary, or add a text geom to annotate your plot. 4.6.1 Smoother On top of the scatter plot, we can add regressed lines and prediction band to it using geom_smooth(). The “loess” method By default, the model for small data is “loess”, we can call the layer either by geom_smooth() or geom_smooth(method ='loess'). In addition, we can adjust option span to control the wiggliness of the line. The higher span is, the less wiggle the line will be. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) p &lt;- ggplot(df, aes(log(Infected + 1), log(Death + 1))) + geom_point() # Use `span` to control the wiggliness of the line # The higher `span` is, the less wiggle the line is p + geom_smooth(method = &#39;loess&#39;, span = 0.5) p + geom_smooth(method = &#39;loess&#39;, span = 1) Figure 4.17: loess smoother examples Linear regression method We can also use method = 'lm' to fit a simple linear model: # Fit a linear model p + geom_smooth(method = &#39;lm&#39;) Figure 4.18: Linear regression estimator. After introducing the idea of individual and collective geoms, we would like to spend the rest of the chapter discussing two important collective plots, time series plots and maps. We will build them step by step from scratch. 4.7 Time Series 4.7.1 Basic line plots In traditional time series plots, we use time as the x-axis variable, and plot the time series using geom_line(). We consider the time series of the daily new infected count for Iowa. df &lt;- slid::state.long %&gt;% dplyr::filter(State == &quot;Iowa&quot;) %&gt;% arrange(DATE) %&gt;% mutate(Y.Infected = Infected - lag(Infected)) %&gt;% dplyr::filter(!is.na(Y.Infected)) To visualize the data, we draw a time series plot first. p &lt;- ggplot(df, aes(DATE, Y.Infected)) + geom_line() + labs(x = &quot;Days&quot;, y = &quot;Count&quot;, title = &#39;Daily new infected cases in Iowa&#39;) p Figure 4.19: Basic time series 4.7.2 Add a second line Next, we display the prediction results on the time series plot. The prediction and prediction intervals for the next 14 days are saved in the dataset: slid::fore. # Data Preparation if(!require(&#39;lubridate&#39;)) install.packages(&#39;lubridate&#39;) library(lubridate) df.pred &lt;- as.data.frame(slid::fore[c(&#39;mean&#39;, &#39;lower&#39;, &#39;upper&#39;)]) names(df.pred) &lt;- c(&#39;mean&#39;, &#39;lower&#39;, &#39;upper&#39;) df.pred$DATE &lt;- tail(df$DATE,1) + c(1:length(slid::fore$mean)) # Add a line for predicted value p + geom_line(mapping = aes(x = DATE, y = mean, color = &#39;Predicted Value&#39;), linetype = &quot;dashed&quot;, # Set the line type in legend key_glyph = &quot;timeseries&quot;, data = df.pred) + scale_color_manual(&quot;&quot;, values = &quot;red&quot;) Figure 4.20: Time series with added predictions 4.7.3 Add ribbons Next, we show the prediction intervals. On top of the line plots, we can add another layer to the existing line, and create a line with two parts. # Add prediction intervals p &lt;- p + geom_ribbon(mapping = aes(x = DATE, y = mean, ymin = lower, ymax = upper, fill = &#39;95% Prediction Intervals&#39;), data = df.pred, alpha = 0.2) + # Add line for predicted value geom_line(mapping = aes(x = DATE, y = mean, color = &#39;Predicted Value&#39;), linetype = &quot;dashed&quot;, data = df.pred, # Set the line type in legend key_glyph = &quot;timeseries&quot;) + scale_color_manual(&quot;&quot;, values = &quot;red&quot;)+ scale_fill_manual(&quot;&quot;, values = &quot;pink&quot;) p Figure 4.21: Time series with ribbons and second line Remarks: the layer added later is put on the top, therefore it is important to keep track of the order you add the layers. 4.7.4 Adjust the scale of time axis There are several ways to define the axis ticks of dates and times. There are the labeled major breaks and further the minor breaks, which are not labeled but marked by grid lines. These can be customized with the arguments date_breaks and date_minor_breaks, respectively. # Adjust the scale of time axis p + scale_x_date( limits = as.Date(c(&quot;2020-10-01&quot;, &quot;2021-01-01&quot;)), date_breaks = &quot;1 month&quot;, date_minor_breaks = &quot;1 week&quot;, date_labels = &quot;%B %Y&quot; ) Figure 4.22: Time series plot with adjusted time range and format In the above syntax, date_labels set to a string of formatting codes, defining order, format and elements to be displayed: %d: day of the month (01-31) %m: month, numeric (01-12) %b: month, abbreviated (Jan-Dec) %B: month, full (January-December) %y: year, without century (00-99) %Y: year, with century (0000-9999) 4.7.5 Add annotations When constructing a data visualization, it is often necessary to make annotations to the data displayed. An annotation supplies additional information about the data being displayed. For example, adding text to a plot is one of the most common forms of annotation. The primary tool for labeling plots is geom_text(), which adds label text at the specified x and y positions. We can also add reference lines to the plot using geom_vline or geom_hline. Figure ?? shows an annotated time series plot with shades and reference lines for each quarter. # Prepare the data df &lt;- df %&gt;% mutate(start = floor_date(DATE, &quot;quarter&quot;)) %&gt;% mutate(end = ceiling_date(DATE, &quot;quarter&quot;)) %&gt;% mutate(quarters = as.factor(quarter(DATE))) df.quarters &lt;- df %&gt;% dplyr::select(start, end, quarters) %&gt;% unique() # Draw the base ggplot ggplot(df, aes(DATE, Y.Infected)) + labs(x = &quot;Days&quot;, y = &quot;Count&quot;, title = &#39;Daily new infected cases in Iowa&#39;) + # Add rectangle for each quarter geom_rect( aes(xmin = (start), xmax = (end), fill = quarters), inherit.aes = F, ymin = -Inf, ymax = Inf, alpha = .5, data = df.quarters) + scale_fill_brewer(palette = &quot;Blues&quot;, aesthetics = &quot;fill&quot;) + # Add vertical line geom_vline(aes(xintercept = as.numeric(start)), data = df, color = &quot;gray&quot;, linetype = &#39;dashed&#39;, size = 0.5) + # Add text geom_text( aes(x = start, y = 0 , label = paste0(&#39;Quarter:&#39;, quarters)), data = df.quarters, inherit.aes = F, size = 3, vjust = 0, hjust = 0, nudge_x = 20) + # Add time series lines geom_line() + geom_line(mapping = aes(x = DATE, y = mean, color = &#39;Predicted Value&#39;), linetype = &quot;dashed&quot;, data = df.pred , key_glyph = &quot;timeseries&quot;) Figure 4.23: Time series plot with shades and reference lines. 4.8 Maps In epidemilogy, data often includes geographical information such as latitude and longitude or regions like country, state or county. To plot these types of data, we can extend an existing visualization onto a map background. We will learn how to make choropleth maps, sometimes called heat maps, using the ggplot2 package. A choropleth map is a map that shows a geographic landscape with units such as countries, states, or watersheds where each unit is colored according to a particular value. # Read map and data library(ggplot2) library(maps) ## ## Attaching package: &#39;maps&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## map library(dplyr) # Load United States state map data MainStates &lt;- map_data(&quot;state&quot;) head(MainStates, 3) ## long lat group order region subregion ## 1 -87.46201 30.38968 1 1 alabama &lt;NA&gt; ## 2 -87.48493 30.37249 1 2 alabama &lt;NA&gt; ## 3 -87.52503 30.37249 1 3 alabama &lt;NA&gt; MainStates &lt;- MainStates %&gt;% mutate(&#39;state&#39; = gsub(&#39; &#39;, &#39;&#39;, MainStates$region)) %&gt;% select(-c(&#39;region&#39;,&#39;subregion&#39;)) head(MainStates, 3) ## long lat group order state ## 1 -87.46201 30.38968 1 1 alabama ## 2 -87.48493 30.37249 1 2 alabama ## 3 -87.52503 30.37249 1 3 alabama state.long.shape &lt;- slid::state.long %&gt;% mutate(&#39;state&#39; = tolower(slid::state.long$State)) %&gt;% right_join(MainStates, by = &#39;state&#39;) %&gt;% select(-state) state.long.shape ## # A tibble: 5,049,525 x 11 ## State Region Division pop DATE Infected Death ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; ## 1 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 2 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 3 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 4 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 5 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 6 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 7 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 8 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 9 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## 10 Alab… South East So… 4.89e6 2020-12-11 288775 4086 ## # … with 5,049,515 more rows, and 4 more variables: ## # long &lt;dbl&gt;, lat &lt;dbl&gt;, group &lt;dbl&gt;, order &lt;int&gt; df &lt;- state.long.shape %&gt;% dplyr::filter(DATE == &#39;2020-12-11&#39;) %&gt;% mutate (Risk = Infected / pop * 1000) 4.8.1 Making a base map Using qplot(), we can obtain our first map like this: qplot(long, lat, geom = &quot;point&quot;, data = df) Figure 4.24: Basic US map with dotted state boundaries We can use the geom_polygon() function to create a map with black borders and add light blue to fill in the map. # Plot all states with ggplot2, black borders and light blue fill ggplot() + geom_polygon(data = df, aes(x = long, y = lat, group = group), color = &quot;black&quot;, fill = &quot;lightblue&quot;) Figure 4.25: US map with colored state areas 4.8.2 Customizing choropleth map Now that we have created a base map of the mainland states, we will color each state according to its the risk. Make the use of slid::ggplot_map_state dataset. # Create a Choropleth map of the United States p &lt;- ggplot() + geom_polygon(data = df, aes(x = long, y = lat, group = group, fill = Risk), color = &quot;white&quot;, size = 0.2) p Figure 4.26: US map with colored state areas according to infected per thousand population Remarks Each state is colored by “Infected per 1000 people” to make the legend easier to read. Border color (white) and line thickness (size = 0.2) are specifically defined within this geom_polygon(). Once a map is created, it is often helpful to modify color schemes, determine how to address missing values (na.values), and formalize labels. Notice that we assigned the graph a name, p. This is particularly useful as we add new components to the map. p + scale_fill_continuous(name = &quot;Infected per 1000 pop&quot;, low = &quot;yellow&quot;, high = &quot;darkred&quot;, limits = c(0, 125), breaks = c(5, 25, 50, 75, 100, 125), na.value = &quot;grey50&quot;) + labs(title = &quot;Infected per 1000 population on 2020-12-11&quot;) Figure 4.27: US map with colored state areas with limits on the values 4.8.3 Overlay polygon maps It is also possible to overlay two polygon maps. The code below creates county borders with a small line size and then adds a thicker line to represent state borders. The alpha = .3 causes the fill in the state map to be transparent, allowing us to see the county map behind the state map. ggplot() + geom_polygon(data = map_data(&quot;county&quot;), aes(x = long, y = lat, group = group), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, size = .1) + geom_polygon(data = map_data(&#39;state&#39;), aes(x = long, y = lat, group = group), color = &quot;black&quot;, fill = &quot;lightblue&quot;, size = .5, alpha = .3) Figure 4.28: US map with colored state areas and county boundaries 4.9 Arranging Plots 4.9.1 Facet Sometimes, we wish to look that the scatterplot within each factor of categorical variables. For example, we may want to look at the situation within each Region in our case. We can split a single plot into many related plots using the function facet_wrap() or facet_grid(): facet_wrap(~variable) will return a symmetrical matrix of plots for the number of levels of variable; facet_grid(. ~variable) will return facets equal to the levels of variable distributed horizontally. facet_grid(variable~.) will return facets equal to the levels of variable distributed vertically. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) p &lt;- ggplot(df, aes(log(Infected + 1), log(Death + 1))) + geom_point(na.rm = TRUE) + aes(color = Region) p Figure 4.29: Facetting examples p + facet_grid(.~Region) Figure 4.30: Facetting examples p + facet_grid(Region~.) Figure 4.31: Facetting examples p + facet_wrap(~Region) Figure 4.32: Facetting examples 4.9.2 Combining plots using patchwork package Before plots can be laid out, they have to be assembled. The goal of patchwork is to make it simple to combine separate ggplots into the same graphic. We can install patchwork from CRAN using if (!require(&#39;patchwork&#39;)) install.packages(&#39;patchwork&#39;) library(patchwork) Let us consider some simple examples. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == as.Date(&#39;2020-12-11&#39;)) p1 &lt;- ggplot(df, aes(log(Infected+1), log(Death + 1))) + geom_point(na.rm = TRUE) p2 &lt;- ggplot(df, aes(log(Death + 1))) + geom_histogram(binwidth = 1) + aes(fill = Region) p3 &lt;- ggplot(df, aes(log(Infected + 1))) + geom_histogram(binwidth = 1) + aes(fill = Region) # Horizontal arrangement p1 + p2 Figure 4.33: Patchwork examples # Vertical arrangement p1 / p2 Figure 4.34: Patchwork examples # Grouped arrangements p1 | (p2 / p3) Figure 4.35: Patchwork examples # Combine three plots p1 + p2 + p3 Figure 4.36: Patchwork examples # Set the number of plots per row p1 + p2 + p3 + plot_layout(ncol = 2) Figure 4.37: Patchwork examples # Combine the duplicate legends p1 + p2 + p3 + plot_layout(ncol = 2, guides = &quot;collect&quot;) Figure 4.38: Patchwork examples # Add title and subtitles p123 &lt;- (p1 | (p2 / p3))+ plot_annotation( title = &quot;Add title here&quot;, caption = &quot;Add caption here&quot; ) p123 Figure 4.39: Patchwork examples 4.10 Output After polishing the figure, we need to save the figure and output it as a readable file for later use. We can either output it in a standard figure format, such as png, tiff, jpeg; or we can save it as an R readable data file, usually referred to as XXX.rds, XXX.rda or XXX.RData, and read by readRDS('XXX.rds'). 4.10.1 Save in figure format # Take a look at the figure before saving # print(p) ggsave(&#39;example_ggplot2.png&#39;, p) # Save the figure in png format ## Saving 7 x 5 in image 4.10.2 Save in RDS format # Save the figure in .rda format saveRDS(p, &#39;example_ggplot2.rds&#39;) # Read the figure in .rda format q &lt;- readRDS(&#39;example_ggplot2.rds&#39;) # print(q) 4.11 Exercises Scatter plot using slid::state.long on 2020-11-01. Create a scatter plot. Treat Infected/1000 as x-axis, and Death/1000 as y-axis. Color the points according to Division. Hint: use aes(color = ). Change the size of the points to be proportional to population. Hint: use aes(size = ). Change the label of x-axis to ‘Infected (in thousands)’, the label of y-axis to ‘Death(in thousands)’. Change the title of the figure as ‘Infected against death on 2020-11-01’. Save the plot to file ‘q1.png’. Time series plot using slid::state.ts for Florida. Obtain the daily new death count for Florida. Create a line plot, time as x-axis, daily new death as y-axis. Add the title “Daily new death count for Florida” to the plot. Using the data up till 2020-11-27, a model obtained the following prediction and 80% prediction intervals for the period from 2020-11-28 to 2020-12-11. DATE Y.Death PI 1 2020-11-28 72 [33, 111] 2 2020-11-29 56 [17, 96] 3 2020-11-30 74 [34, 114] 4 2020-12-01 88 [48, 128] 5 2020-12-02 91 [50, 131] 6 2020-12-03 59 [18, 101] 7 2020-12-04 104 [62, 146] 8 2020-12-05 79 [31, 128] 9 2020-12-06 64 [14, 113] 10 2020-12-07 81 [31, 132] 11 2020-12-08 95 [43, 148] 12 2020-12-09 98 [44, 152] 13 2020-12-10 67 [12, 122] 14 2020-12-11 111 [54, 168] Add another line on your time series plot indicating the predicted daily new death data. Change the title to “Two weeks ahead forecast of the daily new death count for Florida” your plot. Add ribbons on your time series plot in part c to illustrate the prediction intervals in part c. Change the title to “Two weeks ahead forecast of the daily new death count for Florida with 80% prediction intervals”. Save the plot to file ‘q2.png’. For the data slid::state.long and focus on 2020-11-01, do the following: Create a map using Death per 1000 population as the coloring feature. Save the plot to file ‘q3.png’. Combine the three figures and save the plot to file ‘q4.png’. Hint: In R, save each plot with different names (e.g. p1, p2, p3), and then use the patchwork package. References "],
["plotly.html", "Chapter 5 Interactive Visualization 5.1 An Introduction 5.2 Creating Plotly Objects 5.3 Scatterplots and Line Plots 5.4 Pie Charts 5.5 Animation 5.6 Saving HTML 5.7 Exercises", " Chapter 5 Interactive Visualization 5.1 An Introduction As the volume and complexity of infectious disease data increases, public health professionals must synthesize highly disparate data to facilitate communication with the public and inform decisions regarding measures to protect the public’s health. Interactive data visualization allows users the freedom to explore data fully. Here are some key advantages of using interactive data visualization software: Hovering over any data point to see the data behind it; Identifying causes and trends more quickly; Adding multiple highlights and change view subsets of the data by editing options below each graph; Auto-refreshing your visuals to show the most recent data. So far, your primary tool for creating these data visualizations has been “ggplots”. In the past few years, interactive tools for visualization of disease outbreaks has been improving markedly. In this chapter, we will introduce the R plotly package, which allows you to make more professional and interactive graphics, share them on websites, and customize them as you wish. Figure 5.1: A typical data science process. Plotly is an R package for creating interactive, publication-quality graphs. Some of the charts you can do are Basic charts, Statistical charts, Scientific charts, Financial charts, Maps, 3D charts, Subplots, Transforms, Animations. Plotly is built on top of visualization library D3.js, HTML, and CSS. Here are some benefits of using plotly. Plotly is compatible with several languages/ tools: R, Python, MATLAB, Perl, Julia, Arduino. Using plotly, we can easily share interactive plots online with multiple people. Plotly can also be used by people with no technical background for creating interactive plots by uploading the data and using plotly GUI. Plotly is compatible with ggplots in R and Python. Plotly allows embedding interactive plots in websites using iframes or HTML. The syntax for creating interactive plots using plotly is straightforward as well. Suggested references: https://plotly-r.com/overview.html https://plot.ly/r https://plot.ly/r/reference/ Read the book Sievert (2020): Interactive web-based data visualization with R, plotly, and shiny. Read the Cheatsheet from https://images.plot.ly/. Before we begin, please get ready by installing the plotly R package by any of the following methods. Install Plotly You can download the package by using written code below: install.packages(&quot;plotly&quot;) Install from Github Alternatively, you can install the latest development version of plotly from GitHub via the devtools R package: devtools::install_github(&quot;ropensci/plotly&quot;) 5.2 Creating Plotly Objects To create a plotly object, you start with a call to plotly() and pass the data. Next, you decide which graphical representation you want to use: points, lines, bar charts, etc. Then, you customize labels, colors, titles, fonts, etc. Here is a typical code structure: plot_ly(data) %&gt;% add_* (x, y, type, mode, color, size) %&gt;% layout(title, xaxis = list(title, titlefont), yaxis = list(title, titlefont)) In the above code, layout() is used to add/modify part(s) of the graph’s layout. There are a family of add_*() functions, such as add_histogram(), add_trace(), add_lines(), add_pie(), that you can define how to render data into geometric objects. These functions add a graphical layer to a plot. A layer can be considered as a group of graphical elements that can be sufficiently described using only five components: data, aesthetic mappings (e.g., assigning clarity to color), a geometric representation (e.g., rectangles, circles, etc.), statistical transformations (e.g., sum, mean, etc.), and positional adjustments (e.g., dodge, stack, etc.). Here are some arguments that are typically used in the add_*() function: x: values for x-axis; y: values for y-axis; type: to specify the plot that you want to create like “histogram”, “bar”, “scatter”, etc. mode: format in which you want data to be represented in the plot, and possible values are “markers”, “lines, “points”; color: values of same length as x, y and z that represents the color of data points or lines in plot. size: values for same length as x, y and z that represents the size of data points or lines in plot. 5.2.1 Using plot_ly() to create a plotly object Before you try this example, please make sure to install plotly, dplyr and lubridate packages. The lubridate is an R package of choice for working with variables that store dates’ values. library(lubridate) library(dplyr) library(plotly) The county-level dataset is used to create the bar chart below. You can download the county.top10 dataset from the slid R package. This data contains the top 10 counties with the largest number of infected cases on 2020/12/11. library(devtools) install_github(&#39;covid19-dashboard-us/slid&#39;) library(slid) data(county.top10) county.top10 ## ID County State Infection Death ## 176 6037 LosAngeles California 501635 8199 ## 577 17031 Cook Illinois 346004 7282 ## 334 12086 Miami-Dade Florida 253403 3959 ## 75 4013 Maricopa Arizona 245671 4299 ## 2586 48201 Harris Texas 204850 3128 ## 2542 48113 Dallas Texas 156225 1751 ## 1715 32003 Clark Nevada 137100 1962 ## 193 6071 SanBernardino California 120186 1209 ## 297 12011 Broward Florida 118512 1728 ## 2705 48439 Tarrant Texas 116931 1158 Now let’s use the plot_ly() to initialize a plotly object. plot_ly(data = county.top10) %&gt;% add_trace(y = ~Infection, x = ~County, type = &#39;bar&#39;, name = &#39;Infection&#39;) Figure 5.2: Bar chart of the infected count. After running the code, you will see a modebar showing in the top right-hand side of your plotly graph on mouse hover. There are sevel buttons appearing in the modebar. Here are a few things that you can try in the interactive plots: Hovering your mouse over the plot to view associated attributes; Selecting a particular region on the plot using your mouse to zoom; Resetting the axis; Zooming in and zooming out. Next, you can use layout() to modify the layout of a plotly visualization and specify more complex plot arrangements. plot_ly(data = county.top10) %&gt;% add_trace(y = ~Infection, x = ~County, type = &#39;bar&#39;, name = &#39;Infection&#39;) %&gt;% layout(xaxis = list(title = &quot;County&quot;), yaxis = list(title =&quot;Infected Count&quot;), title = &quot;Total Infected Cases on 2020-12-11&quot;) Figure 5.3: Modified bargraph of the infected count. You can also add text labels and annotations to a plotly project in R using add_text(). plot_ly(data = county.top10) %&gt;% add_bars(y = ~Infection, x = ~County, name = &#39;Infection&#39;) %&gt;% add_text( text = ~scales::comma(Infection), y = ~Infection, x = ~County, textposition = &quot;top middle&quot;, showlegend = FALSE, cliponaxis = FALSE ) %&gt;% add_bars(y = ~Death, x = ~County, name = &#39;Death&#39;, color = I(&quot;red&quot;)) %&gt;% add_text( text = ~Death, y = ~Death, x = ~County, textposition = &quot;top middle&quot;, showlegend = FALSE, cliponaxis = FALSE ) %&gt;% layout(xaxis = list(title = &quot;County&quot;), yaxis = list(title = &quot;Number of Cases&quot;), title = &quot;Total Infected/Death Cases on 2020-12-11&quot;) Figure 5.4: Bargraph of the infected count and death count. 5.2.2 Use dplyr verbs to modify data To visualize the states that the counties with the most infected cases locate in, we can use the dplyr verbs to modify data and calculate counts and use add_bars to add a new bar chart. county.top10 %&gt;% group_by(State) %&gt;% summarise(n = n()) %&gt;% plot_ly() %&gt;% add_bars(x = ~State, y = ~n) Figure 5.5: Bargraph of the infected count by adding bars. Next, suppose we are interested in the distribution of the logarithm of the daily new infected cases from 2020-11-12 to 2020-12-11 from all the states in the US. We can use the state.long data in the slid R package, and plot the histogram of log(daily new infected cases) using add_histogram. # Prepare the daily new Infected for each state in the period # from 2020-11-12 to 2020-12-11 slid::state.long %&gt;% dplyr::filter(DATE &lt;= &#39;2020-12-11&#39; &amp; DATE &gt; &#39;2020-11-11&#39;) %&gt;% group_by(State) %&gt;% # Group by State # Create daily new from cum. Infected count mutate(Y.Infected = c(Infected[-length(Infected)] - Infected[-1], 0)) %&gt;% plot_ly() %&gt;% add_histogram(x = ~log(Y.Infected+1)) Figure 5.6: Histogram of the log(daily new infected cases). 5.2.3 Using ggplotly() to create a plotly object The ggplotly() function from the plotly package has the ability to translate ggplot2 to plotly. This functionality can be really helpful for quickly adding interactivity to your existing ggplot2 workflow. We consider the state.long dataset, which includes the variables, cumulative infected cases (Infected). Chapter 4 shows how to draw a simple scatterplot using the reported data on December 11, 2020. Figure 5.7 shows a translated scatterplot from ggplot2 to plotly. df &lt;- slid::state.long %&gt;% dplyr::filter(DATE == &#39;2020-12-11&#39;) p &lt;- ggplot(df, aes(log(Infected), log(Death))) + geom_point() + geom_point(aes(color = Region)) # Translate ggplot2 to plotly ggplotly(p) Figure 5.7: A translated scatterplot from ggplot2 to to plotly. 5.3 Scatterplots and Line Plots The plot_ly() function initiates an object where one or multiple traces can be added to it via functions add_trace() or add_*(). In add_trace(), the layer’s type can be specified using the type argument. For example, some most commonly used types include 'scatter', 'bar', 'box', 'histogram', 'heatmap', etc. Some add_*() functions are specific cases of a trace type. If the type is not specified when adding a layer, a sensible default will be set. We focus on type = 'scatter', which works well in displaying lines and points, such as the time series of infected cases or the number of people vaccinated during the pandemic. 5.3.1 Make a scatterplot We use the state.long data to draw a basic scatterplot with log(Death) vs log(Infected). library(slid) data(state.long) plot_ly(data = state.long %&gt;% filter(DATE == as.Date(&#39;2020-12-11&#39;))) %&gt;% add_trace(x = ~log(Infected), y = ~log(Death), text = ~State, type = &#39;scatter&#39;, mode = &#39;markers&#39;) 5.3.2 Markers We now describe how to change the point colors, and shapes of markers generated using plotly. color: values mapped to relevant fill-color’ attribute(s); I(): avoid mapping a data value to colors and specify the color manually (e.g., color = I(\"red\")). variable: numeric: generate one trace with a filled color determined by the variable value and a color bar as a guide; factor: generate multiple traces with different colors, one for each factor level; symbol: can be specified similarly as color by factor value; I() to set a fixed color. size: for scatterplots, unless otherwise specified via the sizemode, the size argument controls the area of markers and must be a numeric variable. The size argument controls the minimum and maximum size of circles in pixels. Below, we customize the scatterplot and change the size and color of the markers. data(state.long) plot_ly(data = state.long %&gt;% filter(DATE == as.Date(&#39;2020-12-11&#39;))) %&gt;% add_trace(x = ~log(Infected), y = ~log(Death), text = ~State, type = &#39;scatter&#39;, mode = &#39;markers&#39;, # change the size and color of the markers size = ~pop, color = ~Region, marker = list(opacity = 0.5, symbol = &#39;circle&#39;, sizemode = &#39;diameter&#39;)) 5.3.3 A single time series plot We draw a time series of the cumulative infected count for Cook county, IL. # Load data library(slid) data(county.top10.long) # Start plotly from here plot_ly() %&gt;% # add Cook County’s time series using mode: lines+markers add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39; &amp; County == &#39;Cook&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, showlegend = TRUE, name = &#39;mode:lines+markers&#39;, text = &#39;Cook, Illinois&#39;) Figure 5.8: Time series plot of the cumulative infected count for Cook County, IL. 5.3.4 Hover text and template You can add summary statistics or additional information to your plot in the form of tooltips that appear when viewers hover their mouse over areas of your project. There are two main approaches to controlling the tooltip: hoverinfo and hovertemplate. The default value of hoverinfo is x+y+text+name, meaning that plotly.js will use the relevant values of x, y, text, and name to populate the tooltip text. # Start plotly from here plot_ly() %&gt;% # add Cook County’s time series using mode: lines+markers add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39; &amp; County == &#39;Cook&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, showlegend = TRUE, name = &#39;mode:lines+markers&#39;, text = &#39;Cook, Illinois&#39;, hoverinfo = &quot;x+y+text&quot;) To customize the tooltip on your plot, you can use hovertemplate, a template string used to render the information that appears on the hover box. See Chapter 25 of Sievert (2020) for more details on how to design and control the tooltips. # Prepare hover text and formatting label.template &lt;- paste(&#39;County, State: %{text}&lt;br&gt;&#39;, &#39;Date: %{x}&lt;br&gt;&#39;, &#39;Infected Cases: %{y}&#39;) # Start plotly from here plot_ly() %&gt;% # add Cook County’s time series using mode: lines+markers add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39; &amp; County == &#39;Cook&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, showlegend = TRUE, name = &#39;mode:lines+markers&#39;, text = &#39;Cook, Illinois&#39;, hovertemplate = label.template) 5.3.5 Multiple time series plots Using different options in the mode argument Figure 5.9 shows different types of time series plots for the cumulative infected count for three counties by changing the mode argument. # Start plotly from here plot_ly() %&gt;% # add Cook County’s time series using mode: lines+markers add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39; &amp; County == &#39;Cook&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, showlegend = TRUE, name = &#39;mode:lines+markers&#39;, text = &#39;Cook, Illinois&#39;, hovertemplate = label.template) %&gt;% # add LosAngeles county’s time series using mode: lines add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39; &amp; County == &#39;LosAngeles&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines&#39;, showlegend = TRUE, name = &#39;mode:lines&#39;, text = &#39;Los Angeles, California&#39;, hovertemplate = label.template) %&gt;% # add Miami-Dada county’s time series using mode: markers add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39; &amp; County == &#39;Miami-Dade&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;markers&#39;, showlegend = TRUE, name = &#39;mode:markers&#39;, text = &#39;Miami-Dade, Florida&#39;, hovertemplate = label.template) Figure 5.9: Time series plot of the cumulative infected count for three counties. Mapping the value of a variable to color plot_ly() %&gt;% add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, color = ~County, showlegend = TRUE) Controlling the color scale We can use the colors argument to control the color scale: “colorbrewer2.org” palette name (e.g., “YlOrRd” or “Blues”); a vector of colors to interpolate in hexadecimal “#RRGGBB” format; a color interpolation function like colorRamp(). For example, you can define your own color palette: mycol &lt;- c(&quot;#5B1A18&quot;, &quot;#F21A00&quot;, &quot;#D67236&quot;, &quot;#F1BB7B&quot;, &quot;#D8B70A&quot;, &quot;#A2A475&quot;, &quot;#81A88D&quot;, &quot;#78B7C5&quot;, &quot;#3B9AB2&quot;, &quot;#7294D4&quot;, &quot;#C6CDF7&quot;, &quot;#E6A0C4&quot;) plot_ly() %&gt;% add_trace(data = county.top10.long %&gt;% filter(wday(Date) == 1 &amp; type == &#39;Observed&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, color = ~factor(County), colors = mycol, showlegend = TRUE) 5.3.6 More features about the lines We can also alter the thickness of the lines in your time series plot, and make them dashed or dotted using default types or self-defined method. In the following code, we change the line type by the value of variable type by linetype = ~type. plot_ly() %&gt;% add_trace(data = county.top10.long %&gt;% filter(County == &#39;Cook&#39;), x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines&#39;, linetype = ~type, showlegend = TRUE, text = &#39;Cook, Illinois&#39;, hovertemplate = label.template) 5.3.7 Add ribbons You can use the add_ribbons() function to draw a filled area plot, for example, the confidence band or prediction intervals. Its main arguments are: * data: the data * x: x values * ymin: the lower bound of the ribbon * ymax: the upper bound of the ribbon The following code adds the 80% prediction intervals for the cumulative infected cases for Cook County, Illinois. plot_ly(data = county.top10.long %&gt;% filter(County == &#39;Cook&#39;)) %&gt;% add_trace(x = ~Date, y = ~Count, type = &#39;scatter&#39;, mode = &#39;lines&#39;, linetype = ~type, showlegend = TRUE, text = &#39;Cook, Illinois&#39;, hovertemplate = label.template) %&gt;% add_ribbons(x = ~Date, ymin = ~Count_lb, ymax = ~Count_ub, color = I(&quot;#74A089&quot;), opacity = 0.75, name = &quot;80% prediction intervals&quot;) 5.4 Pie Charts We then demonstrate how to make static and interactive pie charts in R. To draw the pie chart, we download the features.state from the slid R package, and the dataset contains four variables: State, Region, Division and pop. We are interested in the composition of the population in each region. 5.4.1 Draw static pie charts using ggplot2 In the following, we will try ggplot2 to draw the pie chart. Before you start to draw the plot, you will need to prepare the data first. # Prepare the data features.region &lt;- features.state %&gt;% group_by(Region) %&gt;% summarize(tpop = sum(pop)) ## `summarise()` ungrouping output (override with `.groups` argument) df &lt;- features.region %&gt;% arrange(desc(Region)) %&gt;% mutate(prop = round(tpop / sum(features.region$tpop), 4) *100) %&gt;% mutate(lab.pos = cumsum(prop)- 0.5*prop ) Next, we will apply the geom_bar and coord_polar functions together with ggplot to display the pie chart; see Figure 5.10. Figure 5.10: A simple ggplot pie chart for population in different regions. 5.4.2 Draw interactive pie charts Now, we will try to use the plotly to make the pie chart, and you will see that the function add_pie() can be implemented easily without data preparition. Figure 5.11: An interactive pie chart for population in different regions. Next, we are interested in finding the composition of the cumulative infected/death cases in each region using add_pie. We can create pie chart subplots by using the domain attribute. It is important to note that the x array sets the horizontal position while the y array sets the vertical. For example, x=[0,0.5], y=[0, 0.5] mean the bottom left position of the plot. ## Warning: `filter_()` is deprecated as of dplyr 0.7.0. ## Please use `filter()` instead. ## See vignette(&#39;programming&#39;) for more help ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. Figure 5.12: Pie charts with subplots: left plot is for infected count, and right plot is for the death count. 5.5 Animation Animated plots are a great way to display the dynamics of the underlying data. Both plot_ly() and ggplotly() support keyframe animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id. This section provides a walk-through for creating an animated plots using the plotly R package. 5.5.1 An animation of the evolution of infected vs. death count Figure 5.13 creates an animation of the evolution in the relationship between the state-level logarithm of cumulative infected count and the logarithm of cumulative death count evolved over time. For simple illustration purpose, we only show the evoluation in December of 2020. The data state.long from slid package provides a daily time series for 48 mainland states and the District of Columbia in the US. Below, we first prepare the data: #install_github(&#39;covid19-dashboard-us/slid&#39;) library(slid) data(state.long) state.long.DEC &lt;- state.long %&gt;% dplyr::filter(DATE &gt; as.Date(&quot;2020-11-30&quot;)) %&gt;% mutate(log.Infected = log(Infected + 1)) %&gt;% mutate(log.Death = log(Death + 1)) Next, we load the required packages. Animations can be created by either using the frame argument in plot_ly() or the frame ggplot2 aesthetic in ggplotly(). Animated plots can be generated with the frame = and ids = arguments in the geom_point() function when using ggplot and ggplotly(). In this case, the data state.long is recorded on a daily basis, so we will assign the DATE variable to frame; each point in the scatterplot represents a state, so we will assign the State variable to ids, which ensures a smooth transition from date to date for the lower 48 states and the District of Columbia in the US: gg &lt;- ggplot(state.long.DEC, aes(log.Infected, log.Death, color = Region)) + geom_point(aes(size = pop, frame = as.numeric(DATE), ids = State)) anim1 &lt;- ggplotly(gg) anim1 Figure 5.13: Your first animated plot between logarithms of the death count and infected count. As long as frame = is provided, an animation is produced with play/pause button(s) and a slider component for controlling the animation. By default, animations populate a play button and slider component for controlling the state of the animation. You can pause an animation by clicking on a relevant location on the slider bar. These components can be removed or customized via the animation_button() and animation_slider() functions. You can control the play button and slider component transition between frames according to rules specified by animation_opts(). Moreover, various animation options, like the amount of time between frames, the smooth transition duration, and the type of transition easing may be altered via the animation_opts() function, too. Here are some animation configuration options in the function animation_opts(): p: a plotly object; frame: the amount of time between frames (this amount should include the transition); transition frame: the duration of the smooth transition between frames; easing: the type of transition easing; redraw = TRUE: trigger a redraw of the plot at the completion of the transition or not; mode: describe how a new animate call interacts with currently-running animations. The detailed options in the above arguments can be found from here. Figure 5.14 illustrates a similar plot as in Figure 5.13 with a slightly different aesthetic style, and it also doubles the amount of time between frames, uses elastic transition easing, places the animation buttons closer to the slider. base &lt;- state.long.DEC %&gt;% plot_ly(x = ~log.Infected, y = ~log.Death, size = ~pop, text = ~State, hoverinfo = &quot;x+y+text&quot;) %&gt;% layout(xaxis = list(type = &quot;log&quot;)) anim2 &lt;- base %&gt;% add_markers(color = ~Region, frame = ~DATE, alpha = 0.8, span = I(2), ids = ~State, colors = &quot;Set1&quot;) %&gt;% animation_opts(frame = 1000, easing = &quot;elastic&quot;, redraw = FALSE) %&gt;% animation_button( x = 1, xanchor = &quot;right&quot;, y = 0, yanchor = &quot;bottom&quot; ) %&gt;% animation_slider( currentvalue = list(type = &quot;date&quot;, font = list(color=&quot;red&quot;)) ) anim2 Figure 5.14: Modified animation with frame = 1000 and elastic easing. The speed at which the animation progresses is controlled by the frame argument, with the default value being 500 milliseconds. In this example, we increase it to 1000 milliseconds, resulting in slower transitions between frames. We can change the way of transition from frame to frame via the easing argument, here easing = \"elastic\" causes the points to bounce when a new frame occurs. See the options of easing from here. The redraw = FALSE argument can improve laggy animations’ performance by not entirely redrawing the plot at each transition. However, in this example, it doesn’t make much difference. 5.5.2 An animation of the state-level time series plot of infected count We now would like to show the state-level time series plot of the infected count. We then show the animation by Region. Since there is no meaningful relationship between objects in different frames of Figure 5.15, the smooth transition duration is set to 0. This helps avoid any confusion that there is a meaningful connection between the smooth transitions. Note that these options control both animations triggered by the play button or via the slider. mycol &lt;- c(&quot;#5B1A18&quot;, &quot;#F21A00&quot;, &quot;#D67236&quot;, &quot;#F1BB7B&quot;, &quot;#D8B70A&quot;, &quot;#A2A475&quot;, &quot;#81A88D&quot;, &quot;#78B7C5&quot;, &quot;#3B9AB2&quot;, &quot;#7294D4&quot;, &quot;#C6CDF7&quot;, &quot;#E6A0C4&quot;) base &lt;- state.long %&gt;% mutate(log.Infected = log(Infected + 1)) %&gt;% plot_ly(x = ~DATE, y = ~log.Infected, frame = ~Region, text = ~State, hoverinfo = &quot;text&quot;) %&gt;% add_lines(color = ~factor(State), colors = mycol, showlegend = FALSE) anim3 &lt;- base %&gt;% layout(xaxis = list(type = &quot;date&quot;, range=c(&#39;2020-01-22&#39;, &#39;2020-12-11&#39;))) %&gt;% animation_opts(1000, easing = &quot;elastic&quot;, redraw = FALSE, transition = 0) anim3 Figure 5.15: Animation of time series plot of infected count by region. 5.6 Saving HTML After polishing the figure, we need to save the figure and animation for later use. We can save any widget made from any htmlwidgets package (e.g., plotly, leaflet, etc) as a standalone HTML file via the saveWidget() function. By default, it produces a completely self-contained HTML file, and all the necessary JavaScript and CSS dependency files are bundled inside the HTML file. 5.6.1 Save as a standalone HTML file # Save plotly object into a standalone html file library(htmlwidgets) saveWidget(fig1, &quot;pie1.html&quot;, selfcontained = T) saveWidget(anim1, &quot;anim1.html&quot;, selfcontained = T) 5.6.2 Save as non-selfcontained HTML file Sometimes, you may want to embed numerous widgets in a larger HTML document and save all the dependency files externally into a single directory. You can do this by setting selfcontained = FALSE and specifying a fixed libdir in saveWidget(). # Save plotly object into a non-selfcontained html file library(htmlwidgets) saveWidget(fig2, &quot;pie2.html&quot;, selfcontained = F, libdir = &quot;lib&quot;) saveWidget(anim2, &quot;anim2.html&quot;, selfcontained = F, libdir = &quot;lib&quot;) 5.7 Exercises We will explore the basic functions of plot_ly using state.long. Install the Github R package slid. library(slid) data(state.long) Create a bar graph for the top ten states with the largest new number of infected cases on December 11, 2020. Create a time series plot for the logarithm of the cumulative infected cases for Iowa. Create a time series plot for the logarithm of the cumulative infected cases for the top ten states with the largest new number of infected cases on December 11, 2020. Create a pie chart for the daily new infected cases on December 11, 2020, for different regions. Save the above plots as an HTML file, and save all the dependency files externally into a single directory using htmlwidgets::saveWidget() with selfcontained = FALSE. Redraw the above plots in (a), (b) and (c) for the death count using the ggplotly() function. Save the above plots as an HTML file, and save all the dependency files externally into a single directory using htmlwidgets::saveWidget() with selfcontained = FALSE. During the COVID-19 pandemic, we are interested in how many tests are coming back positive. The state.long data set comprises state-level cumulative tests. We want to create an animation to demonstrate the weekly test positivity rate for each state based on a 7-day moving average. It is calculated by dividing the state’s new positive counts in the past seven days by the state’s new tests in the past seven days. The PosTest.state.rda and Test.state.rda are the daily reported positive test and daily total test data collected from COVIDTracking Project, and it can be downloaded from the Github slid R package. Load the the datasets to your working directory: library(slid) data(Test.state) data(PosTest.state) change them from the wide form to the long form, and combine them into one dataset. Add a new column of the weekly test positivity rate. Create an animated time series plot for Iowa’s weekly test positivity rate in the past month (30 days) starting from December 1 to December 11, 2020. For example, if I pause on December 7, it should show a time series of Iowa’s weekly test positivity rate from November 8 to December 7. Save your animation in part c as a standalone HTML file and a non-selfcontained HTML file. References "],
["shiny.html", "Chapter 6 R Shiny 6.1 An Introduction to Shiny 6.2 Useful Input Widgets 6.3 Displaying Reactive Output 6.4 Rendering Plotly Inside Shiny", " Chapter 6 R Shiny In infectious disease data learning, interactive visualization makes complex data digestible and useful for users. Shiny offers the ability to develop a graphical user interface (GUI) that can be run locally or deployed online. It has the potential to simplify users’ access to interactive, web-based visualizations greatly. For example, it with multiple views or panels, enabling the users to review their data from different perspectives. Also, Shiny is beneficial to show and communicate updated findings to a broad audience. In this chapter, we focus on linking Plotly graphs with shiny, an open-source R package that provides an elegant and powerful web framework for building web applications using R. Shiny helps you turn your analyses into interactive web applications without requiring HTML, CSS, or JavaScript knowledge. Installation Shiny is available on CRAN, so you can install it in the usual way from your R console: install.packages(&quot;shiny&quot;) 6.1 An Introduction to Shiny A shiny app has two main parts: The user interface, ui, defines how inputs and output widgets are displayed on the page. The UI is customizable, and packages such as “shinydashboard” make it easy to leverage more sophisticated layout frameworks. The server function, server, defines a mapping from input values to output widgets. More specifically, the shiny server is an R function between input values on the client and outputs generated on the webserver. Figure 6.1: An illustration of Shiny Structure. ui.R library(shiny) # Define UI for miles per gallon application shinyUI(pageWithSidebar( # Application title headerPanel(&quot;Hello Shiny!&quot;), sidebarPanel(), mainPanel() )) server.R library(shiny) # Define server logic required to plot variables against mpg shinyServer(function(input, output) { }) Finally, to execute the shiny app, there are two ways. You can run runApp('appname') in an R file, usually named as apps.R, that shares the same directory with a folder, which is under the name 'appname', and contains UI.R and server.R mentioned above. You can define the server function as server and UI function as ui in the same R file, and run shinyApp(ui, server) as follows. library(shiny) # Define UI ui &lt;- shinyUI(pageWithSidebar( # ... Program here )) # Define server logic server &lt;- shinyServer(function(input, output) { # ... Program here }) shinyApp(ui = ui , server = server) In practice, we prefer the first method over the second to manage multiple shiny apps. 6.1.1 Your first shiny app A Shiny application is simply a directory containing a user-interface definition, a server script, and any additional data, scripts, or other resources required to support the application. To get started building the application, create a new empty directory wherever you’d like, then create empty ui.R and server.R files within in. The user interface is defined in a source file named ui.R: library(shiny) # Define UI for application that plots random distributions shinyUI(pageWithSidebar( # Application title headerPanel(&quot;Hello Shiny!&quot;), # Sidebar with a slider input for number of observations sidebarPanel( sliderInput(&quot;obs&quot;, &quot;Number of observations:&quot;, min = 1, max = 1000, value = 500) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) )) The server-side of the application is shown below. It’s very simple – a random distribution with the requested number of observations is generated, and then plotted as a histogram. However, you may also notice that the function which returns the plot is wrapped in a call to renderPlot. See the source file named server.R below. library(shiny) # Define server logic required to generate and plot a random # distribution shinyServer(function(input, output) { # Expression that generates a plot of the distribution. # The expression is wrapped in a call to renderPlot # to indicate that: # # 1) It is &quot;reactive&quot; and therefore should be automatically # re-executed when inputs change # 2) Its output type is a plot # output$distPlot &lt;- renderPlot({ # generate an rnorm distribution and plot it dist &lt;- rnorm(input$obs) hist(dist) }) }) If everything is working correctly you’ll see the application appear in your browser looking something like this: The Hello Shiny example. 6.1.2 Create a new shiny app in RStudio In RStudio, you can create a new directory and an app.R file containing a basic app in one step by clicking File -&gt; New File -&gt; Shiny Web App, then providing Application Name and select Application Type. The RStudio New Shiny Web App Window. 6.1.3 Share your app RStudio offers three ways to host your Shiny app as a web page: Create a free or professional account at http://shinyapps.io, a cloud-based service from RStudio, to host your shiny apps. Click the Publish icon in the RStudio IDE (&gt;=0.99) or run: rsconnect::deployApp(&quot;&lt;path to directory&gt;&quot;) Shiny Server is a companion program to Shiny that builds a web server designed to host Shiny apps. It’s free, open-source, and available from GitHub. 6.2 Useful Input Widgets Shiny also comes pre-packaged with a handful of other useful input widgets, web elements that your users can interact with. Widgets provide a way for your users to send messages to the Shiny app. Shiny widgets collect a value from your user. When a user changes the widget, the value will change as well. Although many shiny apps use them straight “out-of-the-box”, input widgets can easily be stylized with CSS and/or SASS, and even custom input widgets can be integrated. From https://shiny.rstudio.com/, we can explore and select the appropriate input widgets for your interactive visualization. The Basic widgets. selectInput() or selectizeInput() for dropdown menus. numericInput() for a single number. sliderInput() for a numeric range. textInput() for a character string. dateInput() for a single date. dateRangeInput() for a range of dates. fileInput() for uploading files. checkboxInput(), or checkboxGroupInput() or radioButtons() for choosing a list of options. Going forward our focus is to link multiple graphs in shiny through direct manipulation, so we focus less on using these input widgets, and more on using plotly and static R graphics as inputs to other output widgets. 6.3 Displaying Reactive Output You can create reactive output with a two step process. Add an R object to your user interface. Tell Shiny how to build the object in the server function. The object will be reactive if the code that builds it calls a widget value. Step 1: Add an R object to the UI Shiny provides a family of functions that turn R objects into output for your user interface. Each function creates a specific type of output. Output function Creates dataTableOutput: DataTable htmlOutput: raw HTML imageOutput: image plotOutput: plot tableOutput: table textOutput: text uiOutput: raw HTML verbatimTextOutput: text You can add output to the user interface in the same way that you added HTML elements and widgets. Place the output function inside sidebarPanel or mainPanel in the ui. Step 2: Provide R code to build the object. Placing a function in ui tells Shiny where to display your object. Next, you need to tell Shiny how to build the object. We do this by providing the R code that builds the object in the server function. The server function plays a special role in the Shiny process; it builds a list-like object named output that contains all of the code needed to update the R objects in your app. Each R object needs to have its own entry in the list. You can create an entry by defining a new element for output within the server function, like below. The element name should match the name of the reactive element that you created in the ui. You do not need to explicitly state in the server function to return output in its last line of code. R will automatically update output through reference class semantics. Each entry to output should contain the output of one of Shiny’s render* functions. These functions capture an R expression and do some light pre-processing on the expression. You use the render* function that corresponds to the type of reactive object you are making. Specifically, the render function creates: renderDataTable: DataTable renderImage: images (saved as a link to a source file) renderPlot: plots renderPrint: any printed output renderTable: data frame, matrix, other table like structures renderText: character strings renderUI: a Shiny tag object or HTML Each render* function takes a single argument: an R expression surrounded by {}, which can be one simple line of text, or it can involve many lines of code as if it were a complicated function call. You can consider this R expression a set of instructions that you give Shiny to store for later. Shiny will run the instructions when you first launch your app, and then Shiny will re-run the instructions every time it needs to update your object. The Shiny Cheatsheet provides nice summary of the render*() and *Output() functions. The Basic widgets. 6.4 Rendering Plotly Inside Shiny The renderPlotly() function renders anything that the plotly_build() function understands, including plot_ly(), ggplotly(), and ggplot2 objects. It also renders NULL as an empty HTML div, which is handy for certain cases where it doesn’t make sense to render a graph. library(tidyr) library(wesanderson) library(shiny) library(dplyr) library(slid) #library(devtools) #install_github(&#39;https://github.com/covid19-dashboard-us/slid&#39;) Example 1. Top 10 states with the highest daily new infected count ui.R shinyUI(fluidPage( sliderInput(&quot;date.update&quot;, label = h5(&quot;Select date&quot;), min = as.Date(&quot;2020-11-12&quot;), max = as.Date(&quot;2020-12-11&quot;), value = as.Date(&quot;2020-12-11&quot;), timeFormat = &quot;%d %b&quot;, animate = animationOptions(interval = 2000, loop = FALSE) ), # Show a plot of the generated distribution mainPanel( plotlyOutput(&quot;state_daily_bc&quot;, height = &quot;100%&quot;, width = &quot;150%&quot;) ) )) server.R state.daily.bc &lt;- function(date.update){ # load daily new case data for each state dat.sd = slid::dat.sd # select the top 10 states with highest daily new df.sd &lt;- dat.sd[ind.sd[1:10],] df.sd &lt;- df.sd %&gt;% dplyr::select(State, format(date.update, &#39;X%Y.%m.%d&#39;)) %&gt;% mutate(Date &lt;- format(date.update, &#39;%m/%d&#39;)) df.sd$State &lt;- as.character(df.sd$State) names(df.sd) &lt;- c(&#39;State&#39;, &#39;DailyCases&#39;, &#39;Date&#39;) plot.title &lt;- paste0(&quot;New Cases on &quot;, as.character(date.update)) bc.sd &lt;- ggplot(df.sd, aes(State, DailyCases)) + labs(title = plot.title) + xlab(&#39;&#39;) + ylab(&#39;&#39;) + geom_bar(stat = &#39;identity&#39;, fill = &quot;#C93312&quot;) return(bc.sd) } shinyServer(function(input, output) { output$state_daily_bc &lt;- renderPlotly({ ts &lt;- state.daily.bc(input$date.update) }) }) If everything is working correctly you’ll see the application appear in your browser looking something like this: The top ten states with the highest daily new infected count. Example 2. ui.R shinyUI(fluidPage( div(class = &quot;outer&quot;, tags$head(includeCSS(&quot;styles.css&quot;)), plotlyOutput(&quot;us_case_ts&quot;, height = &quot;100%&quot;, width = &quot;100%&quot;), absolutePanel(id = &quot;control&quot;, class = &quot;panel panel-default&quot;, top = 60, left = 70, width = 255, fixed=TRUE, draggable = TRUE, height = &quot;auto&quot;, style = &quot;opacity: 0.8&quot;, selectInput(&quot;plot_type&quot;, label = h5(&quot;Select type&quot;), choices = c(&quot;Original Counts&quot; = &quot;counts&quot;, &quot;Log Counts&quot; = &quot;logcounts&quot;) )# end of selectInput1 ) ) # end of div ) # end of tab ) server.R cols &lt;- c(&quot;#045a8d&quot;, &quot;#cc4c02&quot;) us.case.ts &lt;- function(date.update, plot.type) { # Cum infected cases in Iowa: Observation and Prediction dfplot = slid::dfplot if (plot.type == &#39;counts&#39;){ ts &lt;- ggplot(dfplot, aes(Date, DailyCases, colour = Group)) + ## Plot observed geom_line(colour = &#39;darkgray&#39;) + geom_point() + scale_color_manual(values = c(&quot;Observation&quot; = cols[1], &quot;Prediction&quot; = cols[2])) + ## Change labs labs(title = &#39;Daily new infected cases and prediction&#39;) + xlab(&#39;Date&#39;) + ylab(&#39;Daily new cases&#39;) } else if (plot.type == &#39;logcounts&#39;){ ts &lt;- ggplot(dfplot, aes(Date, logDailyCases, colour = Group) ) + ## Plot observed geom_line(colour = &#39;darkgray&#39;) + geom_point() + scale_color_manual(values = c(&quot;Observation&quot; = cols[1], &quot;Prediction&quot; = cols[2])) + ## Change labs labs(title = &#39;Logarithm of daily new infected count and prediction&#39;) + xlab(&#39;Date&#39;) + ylab(&#39;Log (Daily new cases)&#39;) } return(ts) } shinyServer(function(input, output) { output$us_case_ts &lt;- renderPlotly({ ts &lt;- us.case.ts(date.update = date.update, plot.type = input$plot_type) }) }) If everything is working correctly you’ll see the application appear in your browser looking something like this: The time series plot of the daily new infected cases of Iowa. Remark: There are currently four different modes for mouse click+drag behavior (i.e., dragmode) in plotly.js: zoom, pan, rectangular selection, and lasso selection. Example 3. ui.R shinyUI(fluidPage( div(class=&quot;outer&quot;, tags$head(includeCSS(&quot;styles.css&quot;)), plotlyOutput(&quot;county_risk_ts&quot;, height=&quot;100%&quot;, width=&quot;100%&quot;), absolutePanel(id = &quot;control&quot;, class = &quot;panel panel-default&quot;, top = 60, left = 70, width = 255, fixed=TRUE, draggable = TRUE, height = &quot;auto&quot;, style = &quot;opacity: 0.8&quot;, selectInput(&quot;plot_type&quot;, label = h5(&quot;Select type&quot;), choices = c(&quot;WLR&quot; = &quot;wlr&quot;, &quot;IR&quot; = &quot;localrisk&quot;, &quot;SIR&quot; = &quot;smr&quot;) ) # end of selectInput ) # end of absolutePanel ) # end of div )) ** server.R ** date.update &lt;- as.Date(&#39;2020-12-12&#39;) mycol &lt;- c(&quot;#5B1A18&quot;, &quot;#F21A00&quot;, &quot;#D67236&quot;, &quot;#F1BB7B&quot;, &quot;#D8B70A&quot;, &quot;#A2A475&quot;, &quot;#81A88D&quot;, &quot;#78B7C5&quot;, &quot;#3B9AB2&quot;, &quot;#7294D4&quot;, &quot;#C6CDF7&quot;, &quot;#E6A0C4&quot;) ts.plotly = function(df, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, group = group, mycol, showlegend = TRUE, visible = T, xaxis = xaxis, yaxis = yaxis, legend = legend) { ts &lt;- plot_ly(df) %&gt;% add_trace(x = ~x, y = ~y, type = type, mode = mode, color = ~group, colors = mycol, showlegend = showlegend, visible = visible) %&gt;% layout(xaxis = xaxis, yaxis = yaxis, legend = legend) return(ts) } county.risk.ts = function(date.update, type = &#39;localrisk&#39;){ date.all = date.update - (1:30) date.lag = date.all - 7 County.pop0 &lt;- slid::pop.county County.pop &lt;- County.pop0 %&gt;% filter((!(State %in% c(&quot;Alaska&quot;,&quot;Hawaii&quot;)))) County.pop &lt;- County.pop %&gt;% filter((!(ID %in% c(36005, 36047, 36081, 36085)))) County.pop$ID[County.pop$ID == 46102] = 46113 dat &lt;- slid::I.county dat &lt;- dat %&gt;% filter((!(State %in% c(&quot;Alaska&quot;, &quot;Hawaii&quot;)))) var.names &lt;- paste0(&quot;X&quot;, as.character(date.all), sep = &quot;&quot;) var.names &lt;- gsub(&quot;\\\\-&quot;, &quot;\\\\.&quot;, var.names) var.lag &lt;- paste0(&quot;X&quot;, as.character(date.lag), sep = &quot;&quot;) var.lag &lt;- gsub(&quot;\\\\-&quot;, &quot;\\\\.&quot;, var.lag) tmp &lt;- as.matrix((dat[, var.names] - dat[, var.lag])/7) dat &lt;- dat[, c(&quot;ID&quot;, &quot;County&quot;, &quot;State&quot;, var.names)] smr.c &lt;- sum(County.pop$population)/as.matrix(colSums(dat[,-(1:3)])) I0 &lt;- LogI0 &lt;- LocRisk0 &lt;- SMR0 &lt;- dat # I0[,-(1:3)] &lt;- as.matrix(dat[,-(1:3)]) LogI0[,-(1:3)] &lt;- as.matrix(log(dat[,-(1:3)]+1)) LocRisk0[,-(1:3)] &lt;- sweep(as.matrix(dat[,-(1:3)]), 1, County.pop$population[match(dat$ID, County.pop$ID)], &quot;/&quot;) * 1000 SMR0[,-(1:3)] &lt;- sweep(LocRisk0[,-(1:3)],2,smr.c/10,&quot;*&quot;) WLR0 &lt;- sweep(tmp, 1, County.pop$population[match(dat$ID, County.pop$ID)], &quot;/&quot;) * 1e5 county.dat &lt;- data.frame(Date = date.all) CountyState &lt;- paste(as.character(dat$County), as.character(dat$State), sep = &quot;,&quot;) LogI &lt;- cbind(county.dat,round(t(LogI0[,-(1:3)]),2)) names(LogI) &lt;- c(&quot;Date&quot;, CountyState) LocRisk &lt;- cbind(county.dat,round(t(LocRisk0[,-(1:3)]),2)) names(LocRisk) &lt;- c(&quot;Date&quot;, CountyState) SMR &lt;- cbind(county.dat,t(SMR0[,-(1:3)])) names(SMR) &lt;- c(&quot;Date&quot;, CountyState) WLR &lt;- cbind(county.dat, round(t(WLR0), 2)) names(WLR) &lt;- c(&quot;Date&quot;, CountyState) xaxis.fr &lt;- list(title = &quot;&quot;, showline = FALSE, showticklabels = TRUE, showgrid = TRUE, type = &#39;date&#39;, tickformat = &#39;%m/%d&#39;) legend.fr &lt;- list(orientation = &#39;h&#39;, x = 0, y = -0.05, autosize = F, width = 250, height = 200) if (type == &#39;localrisk&#39;){ ind.county = order(LocRisk0[,var.names[1]], decreasing = TRUE) df.fr &lt;- LocRisk %&gt;% select(c(1, 1 + ind.county[1:10])) %&gt;% gather(key = &quot;County.State&quot;, value = &quot;LogI&quot;, -Date) names(df.fr) &lt;- c(&quot;x&quot;,&quot;group&quot;,&quot;y&quot;) yaxis.fr &lt;- list(title = &quot;Local Risk (Cases per Thousand)&quot;) ts.fr &lt;- ts.plotly(df.fr, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, group = group, mycol, showlegend = TRUE, visible = T, xaxis = xaxis.fr, yaxis = yaxis.fr, legend = legend.fr) }else if (type == &#39;smr&#39;){ ind.county = order(SMR0[,var.names[1]], decreasing = TRUE) df.fr &lt;- SMR %&gt;% select(c(1, 1 + ind.county[1:10])) %&gt;% gather(key = &quot;County.State&quot;, value = &quot;LogI&quot;, -Date) names(df.fr) &lt;- c(&quot;x&quot;,&quot;group&quot;,&quot;y&quot;) yaxis.fr &lt;- list(title = &quot;SMR (%)&quot;) ts.fr &lt;- ts.plotly(df.fr, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, group = group, mycol, showlegend = TRUE, visible = T, xaxis = xaxis.fr, yaxis = yaxis.fr, legend = legend.fr) }else if (type == &#39;logcount&#39;){ ind.county = order(dat[,var.names[1]], decreasing = TRUE) df.fr &lt;- LogI %&gt;% select(c(1, 1 + ind.county[1:10])) %&gt;% gather(key = &quot;County.State&quot;, value = &quot;LogI&quot;, -Date) names(df.fr) = c(&quot;x&quot;, &quot;group&quot;, &quot;y&quot;) yaxis.fr &lt;- list(title = &quot;Log Counts&quot;) ts.fr &lt;- ts.plotly(df.fr, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, group = group, mycol, showlegend = TRUE, visible = T, xaxis = xaxis.fr, yaxis = yaxis.fr, legend = legend.fr) }else if (type == &#39;wlr&#39;){ ind.county &lt;- order(WLR0[, var.names[1]], decreasing = TRUE) df.fr &lt;- WLR %&gt;% select(c(1, 1 + ind.county[1:10])) %&gt;% gather(key = &quot;CountyState&quot;, value = &quot;WLR&quot;, -Date) names(df.fr) &lt;- c(&quot;x&quot;, &quot;group&quot;, &quot;y&quot;) yaxis.fr &lt;- list(title = &quot;WLR (New Cases Per 100K)&quot;) ts.fr &lt;- ts.plotly(df.fr, type = &#39;scatter&#39;, mode = &#39;lines+markers&#39;, group = group, mycol, showlegend = TRUE, visible = T, xaxis = xaxis.fr, yaxis = yaxis.fr, legend = legend.fr) } return(ts.fr) } shinyServer(function(input, output) { output$county_risk_ts &lt;- renderPlotly({ ts &lt;- county.risk.ts(date.update, type = input$plot_type) }) }) If everything is working correctly you’ll see the application appear in your browser looking something like this: The time series plot of risk or log(count) of the top ten counties (based on the corresponding measurement on 12/11/2011). "],
["map.html", "Chapter 7 Interactive Geospatial Visualization 7.1 An Introduction to Leaflet 7.2 The Data Object 7.3 Choropleth map 7.4 Legend 7.5 An Example of County-level Map 7.6 Spot Maps 7.7 Integrating Leaflet with R Shiny 7.8 Exercises", " Chapter 7 Interactive Geospatial Visualization Many spatial and spatiotemporal methods have been developed for early outbreak detection, cluster detection, risk areas, and factors identification, and disease transmission pattern evaluation in the past two decades, thus boosted the investigation of spatial epidemiology. By definition, the focus of spatial epidemiology is the study of the geographical or spatial distribution of health outcomes. It is sometimes interchangeably known as disease mapping. Usually, it has the incidence of disease or prevalence of disease as its main focus. It is a commonplace to consider a geographic dimension included within a research design in infectious disease studies. This may involve initial visualization of the distribution and some simple summary measures. The application of spatial epidemiology methods is fortunately facilitated by the growing development of the open-source community, among which the most widespread and popular is certainly R, a programming language and free software environment for statistical computing and graphics. Disease maps play a key role in descriptive spatial epidemiology. In this chapter, we focus on the interactive geospatial visualization of the data. 7.1 An Introduction to Leaflet The “leaflet” is one of the most popular open-source JavaScript libraries for interactive maps. It’s used by websites ranging from the New York Times and the Washington Post to GitHub and Flickr, as well as GIS specialists like OpenStreetMap, Mapbox, and CartoDB. This R package makes it easy to integrate and control Leaflet maps in R. 7.1.1 Features and installation Unlike static visualization packages such as “ggplot2” or “ggmap”, “leaflet” maps are fully interactive and can include features, such as interactive panning or zooming pop-up tooltips and labels, highlighting or selecting regions. Features Create and customize interactive maps using the “Leaflet” JavaScript library and the “htmlwidgets” package. Compose maps using arbitrary combinations of: Map tiles Markers Polygons Lines Popups GeoJSON The created maps can be used directly from the R console, from “RStudio”, in Shiny applications and R Markdown documents. Easily render spatial objects from the sp or sf packages, or data frames with latitude/longitude columns. Use map bounds and mouse events to drive “Shiny” logic. Augment map features using chosen plugins from the “leaflet” plugins repository. Installation To install this R package, run this command at your R prompt: install.packages(&quot;leaflet&quot;) # to install the development version from Github, run devtools::install_github(&quot;rstudio/leaflet&quot;) Once installed, you can use this package at the R console, within R Markdown documents, and Shiny applications. 7.1.2 Basic Usage Similar to “ggplot2”, leaflet maps are built using layers. We can create a Leaflet map with these basic steps: Step 1. Create a base map widget by calling leaflet(); Step 2. Add features to the map by using layer functions (addTiles(), addMarkers() etc.) to customize the map widget; Step 3. Print the map widget to display it and save it. Here is a base example: library(leaflet) m &lt;- leaflet() %&gt;% addTiles() %&gt;% # Add default OpenStreetMap map tiles addMarkers(lng = 2.2945, lat = 48.8584, popup = &quot;The Eiffel Tower&quot;) m # Print the map 7.2 The Data Object Both leaflet() and the map layer functions have an optional data parameter that is designed to receive spatial data in one of several forms from: the base R lng-lat matrix data frame with lng-lat matrix the sp package: SpatialPoints[DataFrame] SpatialLines[DataFrame] SpatialPolygons[DataFrame] the map package the data frame returned from map() The data argument is used to derive spatial data for functions that need it; for example, if data is a SpatialPolygonsDataFrame object, then calling addPolygons on that map widget will know to add the polygons from the SpatialPolygonsDataFrame. We can always explicitly identify latitude/longitude columns by providing lng`` andlat` arguments to the layer function. Alternatively, for example, we need not specify the values for the arguments lat and lng in addCircles() below, but the columns Lat and Long in the data frame df will be automatically used: # add some circles to a map df = data.frame(Lat = rexp(10) + 23, Long = rnorm(10) + 88) leaflet(df) %&gt;% addTiles() %&gt;% addCircles(data = df, lat = ~Lat, lng = ~Long) The sp package The first general R package to provide classes and methods for spatial data is called sp, which provides classes and methods to create points, lines, polygons, and grids and to operate on them. For example, we can generate the polygons objects using the function Polygon(), and we can also generate SpatialPolygons objects using lists of Polygon. library(sp) library(rgeos) x1 &lt;- c(3, 3, 6, 12, 3) x2 &lt;- c(6, 3, 2, 6, 6) y1 &lt;- c(6, 3, 2, 6) y2 &lt;- c(2, 3, 2, 2) Poly1 &lt;- Polygon(cbind(x1, x2)) Poly2 &lt;- Polygon(cbind(y1, y2)) Polys1 &lt;- Polygons(list(Poly1), &quot;s1&quot;) Polys2 &lt;- Polygons(list(Poly2), &quot;s2&quot;) SPolys &lt;- SpatialPolygons(list(Polys1, Polys2), 1:2) To draw this in leaflet, we use addPolygons(): leaflet(height = &quot;300px&quot;) %&gt;% addPolygons(data = SPolys) The maps package The R maps package contains many outlines of continents, countries, states, and counties. For example, World: world, world.cities, lakes USA: states, county, state, usa and check help(package='maps') for a whole list. The code below shows how to obtain and plot the geospatial object of the states in the US. library(maps) mapStates &lt;- map(&quot;state&quot;, fill = TRUE, plot = FALSE) leaflet(data = mapStates) %&gt;% addTiles() %&gt;% addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE) 7.3 Choropleth map A choropleth map is a map in which a set of pre-defined areas is colored or patterned in proportion to a statistical variable representing an aggregate summary of a geographic characteristic within each area, such as population, different numbers, or rates of disease. To draw a choropleth map, let us start by loading the data into sp objects from JSON using the geojsonio package. This will allow us to easily manipulate the geographic features, and their properties, in R. library(geojsonio) states0 &lt;- geojson_read( x = &quot;https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json&quot; , what = &quot;sp&quot; ) class(states0) In Chapter 3, we have seen an example of merging the states0 data with state.long in the slid R package, and the combined data is saved as states1 in the slid package. In the following, we will work with states1 directly. Now, let’s load the required R packages and data to our working directory. library(geojsonio) library(leaflet) library(dplyr) library(slid) data(state.long) data(states1) # Remove the following regions due to lack of data states1 &lt;- states1 %&gt;% subset(!name %in% c(&#39;Alaska&#39;, &#39;Hawaii&#39;, &#39;Puerto Rico&#39;)) 7.3.1 Create a base map First, we will create a basic states map. The easiest way to add tiles is by calling addTiles() with no arguments: dmap &lt;- leaflet(states1) %&gt;% setView(-96, 37.8, 4, zoom = 4) %&gt;% addTiles() Here, the setView function set the view of the map (center and zoom level) with the following arguments: lng: the longitude of the map center; lat: the latitude of the map center; zoom: the zoom level. Next, if we use the function addPolygons with no additional arguments, then we will obtain the uniform polygons with default styling without any customization. dmap %&gt;% addPolygons() 7.3.2 Color the map Next, we design the color palette for the map. The function colorFactor() maps data values (numeric or factor/character) to colors according to a given palette, which can be provided in a variety of formats. Two often-used arguments are palette: the colors or color function that values will be mapped to; domain: the possible values that can be mapped. pal.state.factor &lt;- colorFactor( palette = &quot;YlOrRd&quot;, domain = states1$Division ) Now, let us color the states according to the division that they belong to. In this case, you can map the value of the division to colors using fillColor = ~pal.state.factor(Division). We can also customize the map, change the color, line type of the state boundary, and other style properties. dmap %&gt;% addPolygons( fillColor = ~pal.state.factor(Division), weight = 1, opacity = 1, color = &quot;white&quot;, dashArray = &quot;3&quot;, fillOpacity = 0.9, layerId = ~name_ns) 7.3.3 Interactive map On the interactive choropleth map, it is possible to zoom and hover a state to get more details about it. The next thing we’ll want is to make the polygons highlight as the mouse passes over them. The addPolygon() function has a highlight argument that makes this simple. We will generate the highlight labels using the sprintf() to obtain a character vector containing a formatted combination of text and variable values. labels_cases &lt;- sprintf( &quot;&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Population: %g M&lt;br&gt; Cumulative Cases: %g&lt;br&gt;Death: %g&lt;br&gt; Infected Cases per Thousand: %g&quot;, states1$name, round(states1$pop / (1e6), 2), states1$Infected, states1$Death, states1$Infect_risk * 1000) %&gt;% lapply(htmltools::HTML) labels_cases[[1]] AlabamaPopulation: 4.89 M Cumulative Cases: 288775Death: 4086 Infected Cases per Thousand: 59.0799 Now let’s display the state names and values to the user. dmap &lt;- dmap %&gt;% addPolygons( fillColor = ~pal.state.factor(Division), weight = 1, opacity = 1, color = &quot;white&quot;, dashArray = &quot;3&quot;, fillOpacity = 0.9, layerId = ~name_ns, # Options to highlight a shape on hover highlight = highlightOptions( weight = 5, color = &quot;#666&quot;, dashArray = &quot;&quot;, fillOpacity = 0.9, bringToFront = TRUE), label = labels_cases, labelOptions = labelOptions( style = list(&quot;font-weight&quot; = &quot;normal&quot;, padding = &quot;3px 8px&quot;), textsize = &quot;15px&quot;, direction = &quot;auto&quot;)) dmap Finally, let us add the legend using the function addLegend(). dmap &lt;- dmap %&gt;% addLegend(pal = pal.state.factor, values = ~Division, opacity = 0.7, title = NULL, position = &quot;bottomright&quot;) dmap 7.4 Legend 7.4.1 Classification schemes We can use the map legend to list the features used on the map and what they depict. Symbols should appear in the legend precisely as they appear in the body of the map. Spatial attribute data can be classified as: Nominal: attributes are nominal if they are given names or titles in order to distinguish one entity from another, for example, the name of a place, urban or rural. Ordinal: attributes are ordinal if their values take on natural order; for instance, the risk level of a disease may be classified with Level 1 representing the lowest risk, level 2 second-lowest, and so on). Numeric: examples of numeric data include temperature, population density, male-to-female ratio, the number of infected cases. Numeric values may vary on a discrete (e.g., integer) or continuous scale. According to Pfeiffer et al. (2008), the continuous attribute data can be divided into six basic classification schemes: Natural breaks: Classes are defined according to apparently natural groupings of data values. The breaks may be defined by breakpoints that are known to be relevant to a particular application, such as fractions and multiples of mobility levels or risk thresholds. Quantile breaks: The data are divided into a pre-determined number of classes that contain an equal number of observations. For example, quintile (five categories) classifications are well suited to displaying linearly distributed data. Equal-interval breaks: The range of the attribute value is calculated and divided into evenly spaced intervals. This method is useful for mapping attribute data that follow a uniform distribution, or if the data ranges are familiar to the user of the map (e.g., herd sizes or temperature bands). Standard deviation classifications: This method takes the distance of the observation from the mean in terms of the number of standard deviations above and below the mean. It is most useful for attribute data that follow a normal distribution. Arithmetic progressions: The widths of category intervals are increased in size at an arithmetic (additive) rate. For example, if the first category is one unit wide and it is decided to increment the width by one unit, the second category would be two units wide, the third three units wide, and so on (1, 3, 6, …). This method is beneficial for skewed distributions. Geometric progressions: The widths of the category intervals are increased in size at a geometric (that is, multiplicative) rate. For example, if the interval width for the first category is two units, the second category would be \\(2 \\times 2 = 4\\) units wide, the third category would be \\(2 \\times 2 \\times 2 = 8\\) units wide, and so on. This method is also very useful for skewed distributions. 7.4.2 Mapping variables to colors Below, we demonstrate how to apply the above classification schemes to map values to colors. For simplicity, we wrap the above code into a function and run it with different palettes, data, labels, variables mapped to fill color, etc. map.state &lt;- function(dat, fill.var, labels, pal, ID = &#39;name_ns&#39;){ dmap &lt;- leaflet(dat) %&gt;% setView(-96, 37.8, 4, zoom = 4) %&gt;% addTiles() %&gt;% addPolygons( fillColor = ~pal(dat@data %&gt;% pull(fill.var)), weight = 1, opacity = 1, color = &quot;white&quot;, dashArray = &quot;3&quot;, fillOpacity = 0.9, layerId = ~dat@data %&gt;% pull(ID), highlight = highlightOptions( weight = 5, color = &quot;#666&quot;, dashArray = &quot;&quot;, fillOpacity = 0.9, bringToFront = TRUE), label = labels, labelOptions = labelOptions( style = list(&quot;font-weight&quot; = &quot;normal&quot;, padding = &quot;3px 8px&quot;), textsize = &quot;15px&quot;, direction = &quot;auto&quot;)) %&gt;% addLegend(pal = pal, values = ~dat@data %&gt;% pull(fill.var), opacity = 0.7, title = NULL, position = &quot;bottomright&quot;) dmap } The family of color*() can be used to generate palette functions easily. There are currently three color functions for dealing with continuous input: colorNumeric, colorBin, and colorQuantile; and one for categorical input, colorFactor. Each function has two required arguments: palette: specifies the colors to map the data to; domain: specifies the range of input values. colorNumeric pal.state.numeric &lt;- colorNumeric( palette = &quot;YlOrRd&quot;, domain = states1$Infected ) map.state(dat = states1, fill.var = &#39;Infected&#39;, labels = labels_cases, pal = pal.state.numeric, ID = &#39;name_ns&#39;) colorQuantile pal.state.quantile &lt;- colorQuantile( palette = &quot;YlOrRd&quot;, domain = states1$Infected, n = 8) map.state(dat = states1, fill.var = &#39;Infected&#39;, labels = labels_cases, pal = pal.state.quantile, ID = &#39;name_ns&#39;) colorBin bins.state&lt;- c(0, 1e4, 5e4, 1e5, 5e5, 1e6, 5e6) pal.state.bins &lt;- colorBin(&quot;YlOrRd&quot;, domain = states1$Infected, bins = bins.state) map.state(dat = states1, fill.var = &#39;Infected&#39;, labels = labels_cases, pal = pal.state.bins, ID = &#39;name_ns&#39;) colorFactor pal.state.factor &lt;- colorFactor(&quot;YlOrRd&quot;, domain = states1$Region) map.state(dat = states1, fill.var = &#39;Region&#39;, labels = labels_cases, pal = pal.state.factor, ID = &#39;name_ns&#39;) 7.5 An Example of County-level Map We are interested in the infection rate at the county level, and would like to draw a county-level choropleth map to illustrate the spatial variation from county to county. First, let us prepare the data. counties0 &lt;- geojson_read( x = &quot;https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json&quot; , what = &quot;sp&quot; ) Next, we combine the county-level data with the state-level data. counties1 &lt;- counties0 counties1@data &lt;- left_join(counties1@data, states1@data %&gt;% select(id, name, density, name_ns, Region, Division, pop, DATE), by = c(&#39;STATE&#39; = &#39;id&#39;)) names(counties1)[8] &lt;- &#39;state_name&#39; names(counties1)[10] &lt;- &#39;state_name_ns&#39; counties1$id &lt;- as.integer(counties1$id) counties1@data &lt;- left_join(counties1@data, pop.county %&gt;% select(ID, population), by = c(&quot;id&quot; = &quot;ID&quot;)) counties1@data &lt;- left_join(counties1@data, I.county %&gt;% select(ID, X2020.12.11), by = c(&quot;id&quot; = &quot;ID&quot;)) counties1@data &lt;- left_join(counties1@data, D.county %&gt;% select(ID, X2020.12.11), by = c(&quot;id&quot; = &quot;ID&quot;)) names(counties1@data)[16:17] &lt;- c(&#39;Infected&#39;, &#39;Death&#39;) names(counties1@data)[13] &lt;- &#39;pop_state&#39; counties1@data &lt;- counties1@data %&gt;% mutate(Infect_risk = Infected/population) counties1[counties1$id == 46113, &#39;population&#39;] &lt;- 14309 The final dataset counties1 can also be downloaded from the slid package directly. Next, we will draw the county-level map. data(counties1) data(states1) counties1 &lt;- counties1 %&gt;% subset(!state_name %in% c(&#39;Alaska&#39;, &#39;Hawaii&#39;, &#39;Puerto Rico&#39;)) states1 &lt;- states1 %&gt;% subset(!name %in% c(&#39;Alaska&#39;, &#39;Hawaii&#39;, &#39;Puerto Rico&#39;)) col2 &lt;- colorRampPalette(c(&quot;#053061&quot;, &quot;#2166AC&quot;, &quot;#4393C3&quot;, &quot;#92C5DE&quot;,&quot;#D1E5F0&quot;, &quot;#FFFFFF&quot;, &quot;#FDDBC7&quot;, &quot;#F4A582&quot;, &quot;#D6604D&quot;, &quot;#B2182B&quot;, &quot;#67001F&quot;)) pal.county.quantile &lt;- colorQuantile( palette = col2(200), domain = counties1$Infect_risk, n = 8) labels_cases.county &lt;- sprintf( &quot;&lt;strong&gt;%s&lt;/strong&gt;, &lt;strong&gt;%s&lt;/strong&gt; &lt;br/&gt;Infection Rate: %g &lt;br&gt; Population: %g K &lt;br&gt; Infected Cases on 2020-12-11: %g&lt;br&gt; Death Cases on 2020-12-11: %g&quot;, counties1$NAME, counties1$state_name, round(counties1$Infect_risk, 3), counties1$population / 1000, counties1$Infected, counties1$Death ) %&gt;% lapply(htmltools::HTML) dmap2 &lt;- leaflet() %&gt;% setView(-96, 37.8, zoom = 4) %&gt;% addTiles() %&gt;% addMapPane(&quot;polygons&quot;, zIndex = 410) %&gt;% addMapPane(&quot;borders&quot;, zIndex = 420) %&gt;% addPolygons( data = states1, fill = FALSE, weight = 1, color = &quot;gray&quot;, fillOpacity = 0, options = pathOptions(pane = &quot;borders&quot;) ) %&gt;% addPolygons( data = counties1, fillColor = ~pal.county.quantile(Infect_risk), weight = 1, opacity = 1, color = &quot;white&quot;, dashArray = &quot;3&quot;, fillOpacity = 0.9, highlight = highlightOptions( weight = 5, color = &quot;#666&quot;, dashArray = &quot;&quot;, fillOpacity = 0.9, bringToFront = TRUE), label = labels_cases.county, layerId = ~id, labelOptions = labelOptions( style = list(&quot;font-weight&quot; = &quot;normal&quot;, padding = &quot;3px 8px&quot;), textsize = &quot;15px&quot;, direction = &quot;auto&quot;), options = pathOptions(pane = &quot;polygons&quot;)) %&gt;% addLegend(data = counties1, pal = pal.county.quantile, values = ~Infect_risk, opacity = 0.7, title = NULL, position = &quot;bottomright&quot;) dmap2 7.6 Spot Maps A spot map is a map showing the geographic location of people with a specific attribute, such as the number of cases of an infectious disease. Spot maps generally are used for clusters or outbreaks with a limited number of cases. Next, we draw a spot map and highlight the top 10 counties with the largest cumulative infected count on December 11, 2020. First, let us prepare the data required. data(features.county) names(features.county) ## [1] &quot;ID&quot; &quot;County&quot; ## [3] &quot;State&quot; &quot;FIPS_C&quot; ## [5] &quot;FIPS_S&quot; &quot;avemort&quot; ## [7] &quot;BlackRate&quot; &quot;HLRate&quot; ## [9] &quot;Gini&quot; &quot;Affluence&quot; ## [11] &quot;HighIncome&quot; &quot;EduAttain&quot; ## [13] &quot;OccupAdv&quot; &quot;MedHouVal&quot; ## [15] &quot;Disadvantage&quot; &quot;PublicAssistance&quot; ## [17] &quot;FemaleLeadRate&quot; &quot;EmployStatus&quot; ## [19] &quot;ViolentCrime&quot; &quot;PropertyCrime&quot; ## [21] &quot;ResidStability&quot; &quot;UrbanRate&quot; ## [23] &quot;HealCovRate&quot; &quot;ExpHealth&quot; ## [25] &quot;Latitude&quot; &quot;Longitude&quot; ## [27] &quot;MF&quot; &quot;dPop_ml2&quot; ## [29] &quot;LOG_pop&quot; &quot;prop_old&quot; ## [31] &quot;BED_SUM&quot; data(county.top10.long) names(county.top10.long) ## [1] &quot;ID&quot; &quot;County&quot; &quot;State&quot; &quot;Date&quot; &quot;Count&quot; ## [6] &quot;type&quot; &quot;Count_lb&quot; &quot;Count_ub&quot; # Combine the datasets with useful variables location.county &lt;- features.county %&gt;% dplyr:: select(ID, Longitude, Latitude) county.top10.today &lt;- county.top10.long %&gt;% select(ID, County, State, Date, Count) %&gt;% filter(Date == &quot;2020-12-11&quot;) df &lt;- left_join(county.top10.today, location.county, key = &quot;ID&quot;) df ## # A tibble: 10 x 7 ## ID County State Date Count Longitude Latitude ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6037 LosAnge… Cali… 2020-12-11 501635 -118. 34.2 ## 2 17031 Cook Illi… 2020-12-11 346004 -87.6 41.9 ## 3 12086 Miami-D… Flor… 2020-12-11 253403 -80.5 25.6 ## 4 4013 Maricopa Ariz… 2020-12-11 245671 -112. 33.3 ## 5 48201 Harris Texas 2020-12-11 204850 -95.4 29.9 ## 6 48113 Dallas Texas 2020-12-11 156225 -96.8 32.8 ## 7 32003 Clark Neva… 2020-12-11 137100 -115. 36.2 ## 8 6071 SanBern… Cali… 2020-12-11 120186 -116. 34.9 ## 9 12011 Broward Flor… 2020-12-11 118512 -80.5 26.2 ## 10 48439 Tarrant Texas 2020-12-11 116931 -97.3 32.8 We start to draw a base map. dmap3 &lt;- leaflet() %&gt;% setView(-96, 37.8, zoom = 4) %&gt;% addTiles() dmap3 Add circles We can add circles to the map to highlight the top ten counties in the data using addCircles(). Circles are similar to circle markers; the only difference is that circles have their radii specified in meters, while circle markers are specified in pixels. As a result, circles are scaled with the map as the user zooms in and out, while circle markers remain a constant size on the screen regardless of zoom level. dmap3 &lt;- dmap3 %&gt;% addCircles(data = df, lng = ~Longitude, lat = ~Latitude, weight = 1, radius = ~sqrt(Count)*200, popup = ~County ) dmap3 Each point can have text added to it using either a popup (appears only on click) or a label (appears either on hover or statically). We will describe the details below. Add popups Popups are small boxes containing some HTML outputs that may include texts or hyperlinks, and it points to a specific point or place on the map. A common use for popups is to have them appear when markers or shapes are clicked. Marker and shape functions in the Leaflet package take a popup argument, where we can pass in HTML commands to attach a simple popup easily. For instance, we can label each county with the name of the county and state, and the reported cumulative infected cases. labels_cases.county &lt;- sprintf( &quot;&lt;strong&gt;%s&lt;/strong&gt;, &lt;strong&gt;%s&lt;/strong&gt; &lt;br/&gt; Cum. Infected Cases on 2020-12-11: %g &lt;br&gt;&quot;, df$County, df$State, df$Count ) %&gt;% lapply(htmltools::HTML) If we only want the information to appear when we click on the point, we should instead use popup = ~labels_cases.county like the following: dmap3 %&gt;% addMarkers(data = df, lng = ~Longitude, lat = ~Latitude, popup = ~labels_cases.county) Add labels A label is textual or HTML content attached to markers and shapes to be always displayed or displayed on mouseover. You don’t need to click a marker/polygon for the label to be shown, unlike popups. dmap3 %&gt;% addMarkers(data = df, lng = ~Longitude, lat = ~Latitude, label = ~labels_cases.county) 7.7 Integrating Leaflet with R Shiny The Leaflet package includes powerful and convenient features for integrating with Shiny applications. Most Shiny output widgets are incorporated into an app by including an output (e.g. plotOutput) for the widget in the UI definition, and using a render function (e.g. renderPlot) in the server function. Leaflet maps are no different; in the UI you call leafletOutput, and on the server side you assign a renderLeaflet call to the output. Inside the renderLeaflet expression, you return a Leaflet map object. 7.8 Exercises Create polygons based on the given coordinates: x1 &lt;- c(6, 8, 8, 6, 6) x2 &lt;- c(6, 6, 4, 4, 6) y1 &lt;- c(5, 6, 8, 10, 5) y2 &lt;- c(8, 3, 2, 8, 8) Draw the two polygons in (a) and (b) on the same map. The Washington Monument is located at longitude -77.0353 and latitude 38.8895. Draw base map and set the default view to and set zoom level 15; Add a popup “Washington Monument” to your base map; Add a label “Washington Monument” to your base map; We will use the state level COVID-19 data (I.state) available in the slid package, and the geospatial information from: library(geojsonio) geojson_read( x = &quot;https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json&quot;, what = &quot;sp&quot;) (a) Calculate the weekly risk of each state and create a `weekly_risk` variable, which contains the number of newly infected cases in the past weeks (December 5, 2020, to December 11, 2020) for each state divided by its population. (b) Draw a choropleth map to display the weekly risk for each state. You can change the opacity and the weight of the borderlines according to your aesthetic preferences. Use `colorBin` to color the states. (c) Generate the highlighted label with the state name and the value of `weekly_risk`, and population, and display the label when the mouse moves over to the state. (d) Save your leaflet map as an HTML file. We will use the county level COVID-19 data (I.county) available in the slid package, and the geospatial information from: library(geojsonio) geojson_read( x = &quot;https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json&quot;, what = &quot;sp&quot; (a) Calculate the weekly risk of each county and create a `weekly_risk` variable, which contains the number of newly infected cases in the past weeks (December 5, 2020, to December 11, 2020) for each county divided by its population. (b) Draw a choropleth map to display the weekly risk for each state. You can change the opacity and the weight of the borderlines according to your aesthetic preferences. Use `colorQuantile` to color the counties. (c) Generate the highlighted label with the county, state name and the value of `weekly_risk`, and population, and display the label when the mouse moves over to the state. (d) Draw a spot map and highlight the top 10 counties with the highest weekly risk in the past week (December 5, 2020, to December 11, 2020). (e) Save each of the above leaflet maps as an HTML file. References "],
["modeling.html", "Chapter 8 Epidemic Modeling 8.1 An Introduction to Epidemic Modeling 8.2 Compartment Models", " Chapter 8 Epidemic Modeling 8.1 An Introduction to Epidemic Modeling 8.2 Compartment Models "],
["regression.html", "Chapter 9 Regression Modeling 9.1 Principles of Regression Modeling 9.2 Area-level Data 9.3 Variable Selection", " Chapter 9 Regression Modeling 9.1 Principles of Regression Modeling 9.2 Area-level Data 9.3 Variable Selection "],
["timeseries.html", "Chapter 10 Time Series Analysis of Infectious Disease Data 10.1 Datasets and R Packages 10.2 Time series plots 10.3 Time Series Decomposition", " Chapter 10 Time Series Analysis of Infectious Disease Data 10.1 Datasets and R Packages 10.2 Time series plots 10.3 Time Series Decomposition "],
["NN.html", "Chapter 11 Neural Networks 11.1 A Single Neuron 11.2 Neural Network Structure", " Chapter 11 Neural Networks 11.1 A Single Neuron 11.2 Neural Network Structure "],
["ensemble.html", "Chapter 12 Hybrid Mdels 12.1 Ensembling Time Series Models 12.2 Model Diagnostics 12.3 Weights Selection Using Cross Validation", " Chapter 12 Hybrid Mdels 12.1 Ensembling Time Series Models 12.2 Model Diagnostics 12.3 Weights Selection Using Cross Validation "],
["references.html", "References", " References "],
["appendix.html", "Appendix", " Appendix "],
["appendix-a.html", "Chapter 13 Appendix A 13.1 R Introduction and Preliminaries 13.2 Starting R 13.3 Export/Import Data", " Chapter 13 Appendix A This Appendix willl introduce you to the basics programming skills in R that are generally unrelated to the use of R as a statistical software such as downloading, reading, manipulating and writing data. 13.1 R Introduction and Preliminaries 13.1.1 The R Environment and Language R is an integrated suite of software facilities for data manipulation, calculation and graphical display. The benefits of R for an introductory student R is free. R is open-source and runs on UNIX, Windows and Macintosh. R has an excellent built-in help system. R has excellent graphing capabilities. Students can easily migrate to the commercially supported S-Plus program if commercial software is desired. R’s language has a powerful, easy to learn syntax with many built-in statistical functions. The language is easy to extend with user-written functions. R is a computer programming language. For programmers it will feel more familiar than others and for new computer users, the next leap to programming will not be so large. What is R lacking compared to other software solutions? There is no commercial support. (Although one can argue the international mailing list is even better) The command language is a programming language so students must learn to appreciate syntax issues etc. R can be regarded as an implementation of the S language which was developed at Bell Laboratories by Rick Becker, John Chambers and Allan Wilks, and also forms the basis of the S-Plus systems. 13.1.2 R and Statistics Many people use R as a statistics system. We prefer to think of it as an environment within which many classical and modern statistical techniques have been implemented. A few of these are built into the base R environment, but many are supplied as packages. There are about 25 packages supplied with R (called “standard” and “recommended” packages) and many more are available through the CRAN family of Internet sites (via http://CRAN.R-project.org) and elsewhere. More details on packages are given later. Most classical statistics and much of the latest methodology is available for use with R, but users may need to be prepared to do a little work to find it. 13.1.3 Obtaining R and installation Obtaining R Sources, binaries, and documentation for R can be obtained via CRAN, the “Comprehensive R Archive Network” whose current members are listed at http://cran.r-project.org/mirrors.html. Installing R under Windows (via http://CRAN.R-project.org) The bin/windows directory of a CRAN site contains binaries for a base distribution and many add-on packages from CRAN to run on Windows 2000 or later on ix86 CPUs (including AMD64/EM64T chips and Windows x64). Your file system must allow long file names (as is likely except perhaps for some network-mounted systems). Installation is straightforward. Just double-click on the icon and follow the instructions. You can uninstall R from the Control Panel or the (optional) R program group on the Start Menu. Installing R under Macintosh (via http://CRAN.R-project.org) Visit the Comprehensive R Archive Network (CRAN) and select a mirror site near you; a list of CRAN mirrors appears at the upper left of the CRAN home page. Click on the link Download R for Mac OS X, which appears near the top of the page; then click on R-X.X.X.pkg (or whatever is the current version of R), which assumes that you are using Mac OS X 10.9 (Mavericks) or higher. You will also find an older version of R if you have an older version of Mac OS X (10.6, Snow Leopard, or higher). Once it is downloaded, double-click on the R installer. You may take all of the defaults. Installing RStudio After you install R, you can install R Studio. Download and install RStudio at https://www.rstudio.com/products/rstudio/download/. Scroll down to “Installers for Supported Platforms” near the bottom of the page. Click on the download link corresponding to your computer’s operating system. 13.2 Starting R RStudio is most easily used in an interactive manner. After installing R and RStudio on your computer, you’ll have two new programs (also called applications) you can open. We’ll always work in RStudio and not in the R application. Figure 13.1 below shows what icon you should be clicking on your computer. Figure 13.1: Icons of R versus RStudio on your computer. After you open RStudio, you should see something similar to Figure 13.2 below. Figure 13.2: RStudio interface to R. Note the three panels divide the screen: the console panel, the files panel, and the environment panel. Throughout this chapter, you’ll come to learn what purpose each of these panels serves. Console: This is the place to write any code that needs to be run. Environment: This lists what variables and objects (referred to in R) are currently available in your working environment. Within the environment window, there are also other tabs such as ‘history’, which shows a history of all code typed in the past. It also has a tab called ‘connection,’ which is meant for connecting to specific databases. This tab is not useful to a beginner. Viewer: For lack of a better way to refer to the third pane, it is referred to here as ‘viewer.’ However, the third pane has several tabs nested within it. The “files” tab shows all the files and folders in your current directory, which the program points to right next to the home icon below the header for the pane. The “plots” tab shows and allows for the saving of any plot output. The “packages” tab shows all the packages that are currently installed. As you start using R-Studio, you will find the need to install many packages and R-Studio makes it easy to do so. 13.2.1 Description of three panels in user interface R Console window The R Environment contains the software’s libraries with all the available datasets, expansion packages and macros. As compared to SAS, the Log and Editor windows are consolidated into a single interface, the “R Console”. Figure 13.3: The R Console. Note: The &gt; is called the prompt. In what follows below it is not typed, but is used to indicate where you are to type if you follow the examples. The Console can be used like a calculator. Below are some examples: 2 + 2 ## [1] 4 (2 - 3) / 6 ## [1] -0.1666667 2 ^ 2 ## [1] 4 sin(pi / 2) ## [1] 1 log(1) ## [1] 0 Results from these calculations can be stored in an object. The &lt;- is used to make the assignment and is read as “gets”. save &lt;- 2 + 2 save The objects are stored in R’s database. When you close R, you will be asked if you would like to save or delete them. This is kind of like the SAS WORK library, but R gives you a choice to save them. To see a listing of the objects, you can do either of the following: ls() objects() To delete an object, use rm() and insert the object name in the parentheses. rm(x, y, z, ink, junk, temp, foo, bar) rm(list=ls()) cleans out all objects from your work space. All objects created during an R session can be stored permanently in a file for use in future R sessions. At the end of each R session, you are given the opportunity to save all the currently available objects. If you indicate that you want to do this, the objects are written to a file called .RData in the current directory (“Save Workspace”), and the command lines used in the session are saved to a file called .Rhistory (“Save History”). save(x, y, z, file = &quot;objects.rdata&quot;) saves objects x, y, z to the file “objects.rdata” in your working directory. load(&quot;objects.rdata&quot;) loads the objects in file “objects.rdata”. R Editor window – type your long R program here Often, you will have a long list of commands that you would like to execute all at once, i.e., a program. Instead of typing all of the code line by line at the R Console, you could type it in the R Script Window. Select File -&gt; New File -&gt; R script to create a new program. Below is what the editor looks like. To run the current line of the code (where the cursor is positioned) or some code highlighted, click “Run”. To save your code as a program outside of R, select File -&gt; Save and make sure to use an .R extension on the file name. Error messages R will provide intuitive error messages regarding the submitted syntax. Unlike in SAS these comments are printed right in the console. 2 + 2 2 + 2 + (3xz 2 + (3 * z) R will provide intuitive error messages regarding the submitted syntax. Unlike in SAS these comments are printed right in the console. 13.2.2 R help To see a listing of all R functions which are “built in”, open the Help by selecting Help -&gt; R Help from the main menu bar. Under Reference, select the link called Packages. All built-in R functions are stored in a package. We have been using functions from the base and stats package. By selecting stats, you can scroll down to find help on the pnorm() function. Note the full syntax for pnorm() is pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) The q value corresponds to the 1.96 can be found by pnorm(1.96) ## [1] 0.9750021 pnorm(q = 1.96) ## [1] 0.9750021 pnorm(q = 1.96, mean = 0, sd = 1) ## [1] 0.9750021 These produce the same results. The other entries in the function have default values set. For example, R assumes you want to work with the standard normal distribution by assigning mean=0 and sd=1 (standard deviation). If you know the exact name of the function, simply type help(function name) at the R Console command prompt to bring up its help in a window inside of R. For example, help(pnorm) brings up Figure 13.4: Figure 13.4: The R help for the R function pnorm(). An alternative is ?pnorm For a feature specified by special characters, the argument must be enclosed in double or single quotes, making it a “character string”: This is also necessary for a few words with syntactic meaning including if and for functions. help(&quot;pnorm&quot;) If you need to use a function but don’t know its exact name or are not sure of its existence. There is a very useful function called apropos(‘argument‘) that lists all functions that contain your argument as part of their names. Note that your argument must be put within either single or double quotation marks. For example, here is what I got when I looked for similar functions containing the string table: apropos(&#39;table&#39;) ## [1] &quot;.S3_methods_table&quot; &quot;[.table&quot; ## [3] &quot;add_table&quot; &quot;aperm.table&quot; ## [5] &quot;as.data.frame.table&quot; &quot;as.relistable&quot; ## [7] &quot;as.table&quot; &quot;as.table.default&quot; ## [9] &quot;db_create_table&quot; &quot;db_drop_table&quot; ## [11] &quot;db_has_table&quot; &quot;db_list_tables&quot; ## [13] &quot;db_write_table&quot; &quot;ftable&quot; ## [15] &quot;ggplot_gtable&quot; &quot;is.relistable&quot; ## [17] &quot;is.table&quot; &quot;margin.table&quot; ## [19] &quot;melt_table&quot; &quot;melt_table2&quot; ## [21] &quot;model.tables&quot; &quot;pairwise.table&quot; ## [23] &quot;print.summary.table&quot; &quot;print.table&quot; ## [25] &quot;prop.table&quot; &quot;r2dtable&quot; ## [27] &quot;read_table&quot; &quot;read_table2&quot; ## [29] &quot;read.ftable&quot; &quot;read.table&quot; ## [31] &quot;spec_table&quot; &quot;spec_table2&quot; ## [33] &quot;summary.table&quot; &quot;table&quot; ## [35] &quot;table1&quot; &quot;table2&quot; ## [37] &quot;table3&quot; &quot;table4a&quot; ## [39] &quot;table4b&quot; &quot;table5&quot; ## [41] &quot;write.ftable&quot; &quot;write.table&quot; ## [43] &quot;xyTable&quot; Note that the argument is a string, so it does not need to be an actual word or name of a function. For example, apropos('tabl') will return the same results. Try it! There may be other times when you want to learn about all functions involving a certain term, but searching for R-related pages on that term returns too many irrelevant results. This term may not even be an R function or command, making the Google search all the more difficult, even with good searching techniques. In these situations, use the help.search(‘argument‘) function. (Again, you need to put your arguments around single or double quotation marks.) This will return all functions with your argument in the help page title or as an alias. For example, I wanted to know about using PDF files in R. I ran help.search(‘pdf’) in R and got the following results. help.search(&quot;pdf&quot;) 13.2.3 Some mathematical expressions Try the following expressions: -2^.5 -2**.5 -(2^.5) (-2)^.5 The first three will give same result. The last produces NaN, not a number. In EXCEL the first produces an error (also in C). It is interpreted just as the 4th expression above. When in doubt, use ( ) to enforce proper order of evaluation. Next try the following factorial(5) produces \\(5! = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdot 5 = 120\\); choose(8,4) produces \\(\\binom{8}{4}=70\\), and sqrt(2) gives \\(\\sqrt{2}=1.414214\\). We will learn more mathematical and statistical expressions in the next few chapters. 13.2.4 R Packages This is a very important topic in R. In SAS and SPSS installations, you usually have everything you have paid for installed at once. R is much more modular. The main installation will install R and a popular set of add‐ons called libraries. Hundreds of other libraries are available to install separately from the Comprehensive R Archive Network, (CRAN). Right under the “viewer” tab, the icon for “setting” allows for changing the working directory or copying and moving files. The tab for “packages,” shows all the packages that are installed and available. Clicking on the checkbox next to the name of the package loads the package for use using the following command, which will appear in the console pane of the interface. Library(Package name) Clicking on the name of the package (under the package tab on the lower right pane) itself brings up the description of what the package does. This is one of the benefits of using R-Studio as opposed to R, which makes it easy to look up all the packages available and what each does. Although the description and examples for packages are sometimes not explicit enough, it is nevertheless a useful starting point for many tasks. The viewer pane tab also makes it easy to install and update packages right from the lower right panel of the user interface. If you want to use functions in other packages, you may need to install and then load the package into R. Packages if they have already been downloaded from a CRAN mirror site can be loaded using this procedure. If the package has not been downloaded, it can be installed using the install.packages(package name) option. Also, an installed package can be loaded by specifying library(name of package). For example, we will be using the ggplot2 package later for data visualization. While in the R console, select Tools -&gt; Install Packages from the main menu. A number of locations around the world will come up. Insert the ggplot2 package and select Install. The package will now be installed onto your computer. This only needs to be done once on your computer. To load the package into your current R session, type library(ggplot2) at the R Console prompt. This needs to be done only once in an R session. If you close R and reopen, you will need to use the library() function again. If the package contains example data sets, you can load them with the data command. Enter data() to see what is available and then data(mydata) to load one named, for example, mydata. Clicking on the link to the package name from within the “packages” tab in the viewer pane provides an overview of what the package does. Here it is useful to spend some time understanding how to use a package. Clicking on the link provides details on its documentation. Next to the package is the package title, which states, “Create Elegant Data Visualisations Using the Grammar of Graphics.” Thus, ggplot2 is a package that makes elegant data visualizations. Clicking on the package link provides an alphabetized list of all that the package does, such as a function called aes that helps construct aesthetic mappings. Another function called borders helps to create a layer of map borders. Clicking on the link aes provides an explanation for what the function does and the way (syntax) it is used. Understanding the structure of this description helps us understand how to use packages. The description of the function within the package has several parts to it as follows: Description: Aesthetic mappings describe how variables in the data are mapped to visual properties (aesthetics) of geoms. Aesthetic mappings can be set in ggplot() and in individual layers. Usage: The second aspect of the description of the function refers to its usages. Arguments: The third part of the structure of a function is referred to as arguments. This describes the objects or variables that this function will operate on. Example: Typically, any description of what a function does is accompanied by an example of how to use it. Thus, understanding how to install a package, the functions it is capable of, along with the examples its description provides makes R very versatile for the user. In the next chapter, we will learn how to use R and its basic functions. 13.2.5 Creating a project and setting working directory Before launching into creating a dataset, it is important to understand how R handles data from a filing and directory perspective. Before creating a dataset, R starts with the creation of a ‘new project.’ A project name is a name given to a folder that will hold everything associated with a specific project such as data, history of commands used, objects (In R, a variable and/or data are stored as “objects”), or variables are created. Along with creating a new project name, it is important to understand the concept of the working directory as R will look for variables and objects or any other files that are being called in the working directory. A simple way to check on the current working directory is to type the command getwd() into the command console. If it is not the intended directory you want to use, the simplest way to change it is by using the “viewer” pane and clicking on the tab that says ‘more.’ Ensuring that your working directory is where you want your files and objects created to be stored is important, especially to a beginner. You may now create a new project by opening R-Studio, clicking on the file, and then ‘new project.’ As shown in Figure 13.5 that opens asks if you would like to open the project in an existing directory, a new one, or simply version control. The existing directory is the directory that is currently the working directory. You may either choose an existing directory or a new one. However, if you choose a new one, you need to make sure that it is selected as the working directory as shown earlier. You may name your project as ‘Learning R.’ Figure 13.5: Interface for creating a project in R. Once the project is created, you will see a .proj file under the files section in the viewer pane, as shown in Figure 13.6. As the figure shows, a new project called ‘Learning R.rproj’ has been created in the directory ~/STAT 480/Learning R. Any work done will now be stored in this directory (by setting it as the working directory) and in this project as long as it is saved when you exit. Figure 13.6: Directory with new project. 13.3 Export/Import Data In this section, you’ll learn how to read plain-text rectangular files into R, and how to export data from R to txt, csv, and R data file formats. First, we need is an idea of where the files are stored with R and how to manipulate those files. Every R session has a default location on your operating system’s file structure called the working directory. You need to keep track and deliberately set your working directory in each R session. If you read or write files to disk, this takes place in the working directory. If you don’t set the working directory to your desired location, you could easily write files to an undesirable file location. Working Directory The getwd() function tells you what the current working directory is: getwd() To change the working directory, use the setwd() function. Be sure to enter the working directory as a character string. This example shows how to change your working directory to a folder called “F:/STAT480/R”: setwd(&quot;F:/STAT480/R&quot;) getwd() Note that the separator between folders is “/”, as it is on Linux and Mac systems. When working in Windows, you need to either use “/” or “”. 13.3.1 Data Export Using function cat() The function cat is useful for producing output in user-defined functions. cat(&quot;Good morning!&quot;,&quot;\\n&quot;) #\\n: newline ## Good morning! cat(file = &quot;test.txt&quot;, &quot;123456&quot;, &quot;987654&quot;, sep = &quot;\\n&quot;) Using function print() The function print prints its argument. It is a generic function which means that new printing methods can be easily added for new classes. print(&quot;Good morning!&quot;) ## [1] &quot;Good morning!&quot; Write a matrix or data frame to file The commonest task is to write a matrix or data frame to file as a rectangular grid of numbers, possibly with row and column labels. This can be done by the functions write.table and write. Command to copy and paste from R into Excel or other programs. It writes the data of an R data frame object into the clipboard from where it can be pasted into other applications. age &lt;- 18:29 height &lt;- c(76.1, 77, 78.1, 78.2, 78.8, 79.7, 79.9, 81.1, 81.2, 81.8, 82.8, 83.5) village &lt;- data.frame(age = age,height = height) # Write village into clipboard write.table(village, &quot;clipboard&quot;, sep = &quot;\\t&quot;, col.names = NA, quote = F) Remark: The argument quote is a logical value (TRUE or FALSE) or a numeric vector. If TRUE, any character or factor columns will be surrounded by double quotes. If FALSE, nothing is quoted. The argument col.names= NA makes sure that the titles align with columns when row/index names are exported (default). Write data frame to a tab-delimited text file. write.delim(village, file = &quot;village.txt&quot;) # provides same results as read.delim write.table(village, file = &quot;village.txt&quot;, sep = &quot;\\t&quot;) Write data to csv files: write.csv(village, file = &quot;village.csv&quot;) Write matrix data to a file. x &lt;- matrix(1, 20, 20) write(x, file = &quot;file path&quot;, ncolumns = 20) Remark: write.table() is the multipurpose work-horse function in base R for exporting data. The functions write.csv() and write.delim() are special cases of write.table() in which the defaults have been adjusted for efficiency. 5 .RData files The best way to store objects from R is with .RData files. .RData files are specific to R and can store as many objects as you’d like within a single file. ** The save() function age &lt;- 18:29 height &lt;- c(76.1, 77, 78.1, 78.2, 78.8, 79.7, 79.9, 81.1, 81.2, 81.8, 82.8, 83.5) village &lt;- data.frame(age = age, height = height) # Save the object as a new .RData file save(village, file = &quot;data/village.rda&quot;) To save selected objects into one .RData file, use the save() function. When you run the save() function with specific objects as arguments, (like save(a, b, c, file = \"myobjects.RData\") all of those objects will be saved in a single file called myobjects.RData. For example, let’s create a few objects corresponding to a study. # Create two objects student.df &lt;- data.frame(id = 1:5, sex = c(&quot;m&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;, &quot;m&quot;), score = c(90, 80, 97, 62, 82)) score.by.sex &lt;- aggregate(score ~ sex, FUN = mean, data = student.df) # Save two objects as a new .RData file save(student.df, score.by.sex, file = &quot;data/student.rda&quot;) 13.3.2 Data Import The load() function To load an .RData file, that is, to import all of the objects contained in the .RData file into your current workspace, use the load() function. For example, to load the three specific objects that I saved earlier (study1.df, score.by.sex) in study1.rda, I’d run the following: # Load objects in village.rda into my workspace load(file = &quot;data/village.rda&quot;) To load all of the objects in the workspace that we have saved to the data folder in a working directory named projectnew.rda, we can run the following: # Load objects in projectnew.rda into my workspace load(file = &quot;data/projectnew.rda&quot;) The read.table() function Large data objects will usually be read as values from external files rather than entered during an R session at the keyboard. R input facilities are simple, and their requirements are fairly strict and even rather inflexible. If variables are to be held mainly in data frames, as we strongly suggest they should be, an entire data frame can be read directly with the read.table() function. There is also a more primitive input function, scan(), that can be called directly. For more details on importing data into R and also exporting data, see the R Data Import/Export manual. To read an entire data frame directly, the external file will typically have a special form. The first line of the file should have a name for each variable in the data frame. Each additional line of the file has its first item, a row label, and the values for each variable. By default, numeric items (except row labels) are read as numeric variables and non-numeric variables, such as name and gender in the above example, as factors. The function read.table() can then be used to read the data frame directly. For the file, scores_names.txt, you might want to omit, including the row labels, directly and use the default labels. In this case, the file may omit the row label column as in the following. scores &lt;- read.table(&quot;scores_names.txt&quot;, header = TRUE) scores[[&#39;gender&#39;]] scores[[&#39;aptitude&#39;]] where the header=TRUE option specifies that the first line is a line of headings, and hence, by implication from the form of the file, that no explicit row labels are given. This can be changed if necessary. scores &lt;- read.table(&quot;scores_names.txt&quot;, colClasses = c(&quot;character&quot;, &quot;character&quot;, &quot;integer&quot;, &quot;integer&quot;), header = TRUE) &gt; scores[[&#39;gender&#39;]] If the values are separated by commas or another “delimiter,” we have to specify the delaminating character(s). For example, look at the file reading.txt on the Blackboard folder. reading &lt;- read.table(&quot;reading.txt&quot;, sep = &quot;,&quot;) # names() is to get or set the names of an object. names(reading) = c(&quot;Name&quot;, &quot;Week1&quot;, &quot;Week2&quot;, &quot;Week3&quot;, &quot;Week4&quot;, &quot;Week5&quot;) print(reading) If sep = \"\" (the default for read.table) the separator is ‘white space’, that is one or more spaces, tabs, newlines or carriage returns. The read.csv() function Alternatively, you may have data from a spreadsheet. The simplest way to enter this into R is through a file format. Typically, this is a CSV format (comma-separated values). First, save the data from the spreadsheet as a CSV file say data.csv. Then the R command read.csv will read it in as follows x &lt;- read.csv(file=&quot;data.csv&quot;) CSV file can be comma delimited or tab or any other delimiter specified by parameter sep =. If the parameter header = is TRUE, then the first row will be treated as the row names. read.csv(file, header = FALSE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;, fill = TRUE, comment.char = &quot;&quot;, ...) read.csv2(file, header = TRUE, sep = &quot;;&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;,&quot;, fill = TRUE, comment.char = &quot;&quot;, ...) file: file name header: 1st line as header or not, logical sep: field separator quote: quoting characters … The difference between read.csv and read.csv2 is the default field seperator, as “,” and “;” respectively. Following is a csv file example: t1 t2 t3 t4 t5 t6 t7 t8 r1 1 0 1 0 0 1 0 2 r2 1 2 2 1 2 1 2 1 r3 0 0 0 2 1 1 0 1 r4 0 0 1 1 2 0 0 0 r5 0 2 1 1 1 0 0 0 r6 2 2 0 1 1 1 0 0 r7 2 2 0 1 1 1 0 1 r8 0 2 1 0 1 1 2 0 r9 1 0 1 2 0 1 0 1 r10 1 0 2 1 2 2 1 0 r11 1 0 0 0 1 2 1 2 r12 1 2 0 0 0 1 2 1 r13 2 0 0 1 0 2 1 0 r14 0 2 0 2 1 2 0 2 r15 0 0 0 2 0 2 2 1 r16 0 0 0 1 2 0 1 0 r17 2 1 0 1 2 0 1 0 r18 1 1 0 0 1 0 1 2 r19 0 1 1 1 1 0 0 1 r20 0 0 2 1 1 0 0 1 x &lt;- read.csv(&quot;readcsv.csv&quot;, header = T, dec = &quot;.&quot;, sep = &quot;\\t&quot;) is.data.frame(x) Import an Excel file into R You can import an excel file using the readxl package. To start, here is a template that you can use to import an Excel file into R: library(&quot;readxl&quot;) read_excel(&quot;&lt;name and extension of your file&gt;&quot;) If you want to import a specific sheet within the Excel file, you may use this template: library(&quot;readxl&quot;) read_excel(&quot;&lt;name and extension of the file&gt;&quot;, sheet = &quot;sheet name&quot;) If you want to set a three column excel sheet to contain the data as dates in the first column, characters in the second, and numeric values in the third, you would need the following lines of code: library(&quot;readxl&quot;) read_excel(&quot;&lt;name and extension of your file&gt;&quot;, col_types = c(&quot;date&quot;, &quot;numeric&quot;, &quot;text&quot;)) Accessing built-in datasets Around 100 datasets are supplied with R (in package datasets), and others are available in packages (including the recommended packages supplied with R). To see the list of datasets currently available use data(). As from R version 2.0.0 all the datasets supplied with R are available directly by name. AirPassengers However, many packages still use the earlier convention in which data was also used to load datasets into R, for example, data(AirPassengers) and this can still be used with the standard packages. In most cases this will load an R object of the same name. However, in a few cases it loads several objects, so see the on-line help for the object to see what to expect. Loading data from other R packages To access data from a particular package, use the package argument, for example, data(package = &quot;rpart&quot;) data(Puromycin, package = &quot;datasets&quot;) Figure 13.7 shows a subset oof supported file formats. Figure 13.7: A non-inclusive list of supported file formats. "],
["appendix-b.html", "Chapter 14 Appendix B 14.1 Epidemic Data 14.2 Other Factors 14.3 Data Sets", " Chapter 14 Appendix B Since the first infected case reported in December 2019, the outbreak of Coronavirus disease (COVID-19) has unfolded across the globe. In the US, coronavirus has infected more than five million people and killed over 160,000 people, as of the time of writing. While essential public health, economic and social science research in measuring and modeling COVID-19 and its effects is underway, reliable and accurate datasets are vital for scientists to conduct related research and for governments to make better decisions (Killeen et al. 2020). Unfortunately, errors could occur in the data collection process, especially under such a pandemic. In this work, we focus on the data collection, comparison, data inconsistency detection, and the corresponding curating. Living through unprecedented times, governments must rely on timely, reliable data to make decisions to mitigate harm and support their citizens. Every day, several volunteer groups and organizations work very hard on collecting data on COVID-19 from all the counties and states in the US. There are four primary sources, including (1) the New York Times (NYT), (2) the COVID Tracking Project at the Atlantic (Atlantic), (3) the data repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU), and (4) USAFacts. We collect the epidemic data up to county level in the US along with control measures and other local information, such as socioeconomic status, demographic characteristics, healthcare infrastructure, and other essential factors to analyze the spatiotemporal dynamic pattern of the spread of COVID-19. Our data covers about 3,200 county-equivalent areas from 50 US states and the District of Columbia. A live version of the data analysis will be continually updated on the COVID-19 US Dashboard and the Github Repository. 14.1 Epidemic Data The daily counts of cases and deaths of COVID-19 are crucial for understanding how this pandemic is spreading. Thanks to the contribution of the data science communities across the world, multiple sources are providing the COVID-19 data with different precision and focus. In this book, we consider the reported cases from the following four sources: the NYT, the Atlantic, the JHU, and the USAFacts. To clean the data, we first fetch data from the above four sources and compile them into the same format for further comparison and cross-validation. 14.1.1 State level In the state level epidemic data, we include the following variables. Among those variables, the variable State can be used as the key for data merge. State: name of state. There are 48 mainland US states and the District of Columbia. XYYYY.MM.DD: cumulative infection or death cases related to the date of YYYY.MM.DD. YYYY, MM, and DD represent year, month and day, re- spectively. It starts from X2020.01.22. For example, the variable X2020.01.22 is either infection or death cases in a certain state (State) on 01/22/2020. 14.1.2 County level For county-level data, two more county-specific variables are included. As the key of this table, variable ID can be used for future data merge. ID: county-level Federal Information Processing System (FIPS) code, which uniquely identifies the geographic area. The number has five digits, of which the first two are the FIPS code of the state to which the county belongs. County: name of county matched with ID. There are about 3,200 counties and county-equivalents (e.g. independent cities, parishes, boroughs) in the US. State: name of state matched with ID. There are 50 states and the District of Columbia in the US. XYYYY.MM.DD: cumulative infection or death cases related to the date of YYYY.MM.DD. YYYY, MM, and DD represent year, month and day, respectively. It starts from X2020.01.22. For example, the variable X2020.01.22 is either infection or death cases in a certain (County) on 01/22/2020. 14.2 Other Factors When analyzing the reported cases of COVID-19, many other factors may also contribute to the temporal or spatial patterns; see the discussions in (Wang et al. 2020). For example, local features, like socioeconomic and demographic factors, can dramatically influence the course of the epidemic, and thus, the spread of the disease could vary dramatically across different geographical regions. Therefore, these datasets are also supplemented with the population information at the county level in our repository. We further classify these factors into the following six groups. 14.2.1 Policy Data In a race to stunt the spread of COVID-19, federal, state and local governments have issued various executive orders. Government declarations are used to identify the dates that different jurisdictions implemented various social distancing policies (emergency declarations, school closures, bans on large gatherings, limits on bars, restaurants and other public places, the deployment of severe travel restrictions, and “stay-at-home” or “shelter-in-place” orders). For example, President Trump declared a state of emergency on March 13, 2020, to enhance the federal government response to confront COVID-19. Later in the past spring, at least 316 million people in at least 42 states, the District of Columbia and Puerto Rico were urged to stay home. Since the late April, all 50 states in the US began to reopen successively, due to the immense pressures of the crippled economy and anxious public. A state is categorized as “reopening” once its stay-at-home order lifts, or once reopening is permitted in at least one primary sector (restaurants, retail stores, personal care businesses), or once reopening is permitted in a combination of smaller sectors. We compiled the dates of executive orders by checking national and state governmental websites, news articles, and press releases. 14.2.2 Demographic Characteristics In the demographic characteristics category, we consider the factors describing racial, ethnic, sexual, and age structures. These variables are extracted from the 2010 Census, and the 2010–2018 American Community Survey (ACS) Demographic and Housing Estimates. Specifically, we include the following six variable AA_PCT: the percent of the population who identify as African American; HL_PCT: the percent of the population who identify as Hispanic or Latino; Old_PCT: the percent of aged people (age &gt;= 65 years); Sex_ratio: the ratio of male over female; PD_log: the logrithm of the population density per square mile of land area; Pop_log: the logarithm of local population; Mortality: the five-year (1998-2002) average mortality rate, measured by the total counts of deaths per 100, 000 population in a county. 14.2.3 Healthcare Infrastructure We also incorporate several features related to the healthcare infrastructure at the county level in the datasets, including the percent of persons under 65 years without health insurance, the local government expenditures for health per capita, and total bed counts per 1,000 population. NHIC_PCT: the percent of persons under 65 years without health insurance EHPC: the local government expenditures for health per capita; TBed: the total bed counts per 1,000 population. 14.2.4 Socioeconomic Status We consider diverse socioeconomic factors in the county level datasets. All of these factors collected from 2005–2009 ACS five-year estimates. Affluence: social affluence generated by factor analysis from HighIncome, HighEducation, WCEmployment and MedHU; HIncome_PCT: the percent of families with annual incomes higher than $75,000; HEducation_PCT: the percent of the population aged 25 years or older with a bachelor’s degree or higher; MedHU: the median value of owner-occupied housing units; Disadvantage: concentrated disadvantage obtained by factor analysis from HHD_PAI_PCT, HHD_F_PCT and Unemployment_PCT; HHD_PAI_PCT: the percent of the households with public assistance income; HHD_F_PCT: the percent of households with female householders and no husband present; Unemployment_PCT: civilian labor force unemployment rate; Gini: the Gini coefficient, a measure for income inequality and wealth distribution in economics. 14.2.5 Environmental Factor We also collect environmental factors that might affect the spread of epidemics significantly, such as the urban rate and crime rate. UrbanRate: urban rate; ViolentCrime: the total number of violent crimes per 1,000 population; PropertyCrime: the total number of property crimes per 1,000 population; ResidStability: the percent of the population residence in the same house for one year and over. 14.2.6 Mobility Another category of factors in the literature that affects the spread of infectious diseases significantly is the mobility; for example, movements of people from neighborhoods. We collect the mobility data from the Bureau of Transportation Statistics. Number of trips X – XX: number of trips by residents greater than X miles and shorter than XX miles. There are 10 different trip ranges: “&lt;= 1”, “1 – 3”, “3 – 5”, “5–10”, “10 – 25”, “25 – 50”, “50 – 100”, “100 – 250”, “250 – 500”, and \" &gt; 500\". Population Stay at Home: number of residents staying at home, that is, persons who make no trips with a trip end more than one mile away from home. 14.2.7 Geographic Information The longitude and latitude of the geographic center for each county in the US are available in Gazetteer Files: https://www2.census.gov/geo/docs/maps-data/data/gazetteer/2019_Gazetteer. 14.3 Data Sets 14.3.1 Chapter 2 I.county: a 3104 by 328 dataframe with columns ID, County, State and dates fromX2020.12.11 to X2020.01.22. pop.county: a 3142 by 4 dataframe with columns ID, County, State and population. Each row of the dataframe stands for one county along with its population. state.long: a 15925 by 7 dataframe with columns State, Region, Division, pop, DATE, Infected and Death. Each row of the dataframe stands for one state on a specific date. I.state/I.state.wide: a 49 by 326 dataframe with columns State and dates fromX2020.12.11 to X2020.01.22. Each row of the dataframe stands for the time series of infected cases for one state. I.state.long: a 15925 by 3 dataframe with columns State, DATE and Infect. Each row of the dataframe stands for one state on a specific date. 14.3.2 Chapter 3 "]
]
